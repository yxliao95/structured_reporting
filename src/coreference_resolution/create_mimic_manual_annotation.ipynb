{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting ready for manual annotation on MIMIC-CXR dataset\n",
    "\n",
    "There are 227835 reports in the dataset, each report has multiple section, such as findings and imporession.\n",
    "\n",
    "1. Balanced sampling:  The anatomy and observation could be quite different. We don't want to sample on the same anatomy and observation.\n",
    "   1. To do so, we can statistic on which anatomy appears how many times on which report.\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"../../../../git_clone_repos/fast-coref/src\")\n",
    "\n",
    "import os\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from IPython.display import display, HTML\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from multiprocessing import Event\n",
    "from common_utils.data_loader_utils import load_mimic_cxr_bySection\n",
    "from common_utils.coref_utils import resolve_mention_and_group_num\n",
    "from common_utils.file_checker import FileChecker\n",
    "from common_utils.common_utils import check_and_create_dirs\n",
    "\n",
    "FILE_CHECKER = FileChecker()\n",
    "START_EVENT = Event()\n",
    "\n",
    "mpl.style.use(\"default\")\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = None\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"nlp_ensemble\"):\n",
    "        config = compose(config_name=\"data_preprocessing\", overrides=[\"+nlp_ensemble@_global_=mimic_cxr\"])\n",
    "        section_name_cfg = config.name_style.mimic_cxr.section_name\n",
    "        output_section_cfg = config.output.section\n",
    "        input_path = config.input.path\n",
    "        data_size, pid_list, sid_list, section_list = load_mimic_cxr_bySection(input_path, output_section_cfg, section_name_cfg)\n",
    "\n",
    "# Sort\n",
    "s_list, f_list, i_list, pfi_list, fai_list = zip(*sorted(zip(sid_list, section_list[0][1], section_list[1][1], section_list[2][1], section_list[3][1])))\n",
    "sid_list = s_list\n",
    "section_list = [\n",
    "        (\"findings\", f_list),\n",
    "        (\"impression\", i_list),\n",
    "        (\"provisional_findings_impression\", pfi_list),\n",
    "        (\"findings_and_impression\",fai_list)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def batch_processing(sid, input_path):\n",
    "    START_EVENT.wait()\n",
    "    df_spacy = pd.read_csv(input_path, index_col=0, na_filter=False)\n",
    "\n",
    "    word_counter = Counter()\n",
    "    word_counter.update(df_spacy.loc[:,\"[sp]token\"].to_list())\n",
    "\n",
    "    return sid, word_counter\n",
    "\n",
    "\n",
    "for section_entry in os.scandir(\"../../output/mimic_cxr/nlp_ensemble/spacy\"):\n",
    "    if section_entry.is_dir():\n",
    "        total_word_counter = Counter()\n",
    "        \n",
    "        tasks = []\n",
    "        with ProcessPoolExecutor(max_workers=14) as executor:\n",
    "            for report_entry in tqdm(os.scandir(section_entry.path)):\n",
    "                if FILE_CHECKER.ignore(os.path.abspath(report_entry.path)):\n",
    "                    continue\n",
    "                sid = report_entry.name.rstrip(\".csv\")\n",
    "                tasks.append(executor.submit(batch_processing, sid, report_entry.path))\n",
    "\n",
    "            START_EVENT.set()\n",
    "\n",
    "            # Receive results from multiprocessing.\n",
    "            for future in tqdm(as_completed(tasks), total=len(tasks)):\n",
    "                sid, word_counter = future.result()\n",
    "                total_word_counter.update(word_counter)\n",
    "\n",
    "            START_EVENT.clear()\n",
    "        \n",
    "        print(\"Section:\", section_entry.name)\n",
    "        print(total_word_counter.most_common(100))\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The scatter plot of \"number of tokens\" and \"number of coreference\" per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "scoref_dir = \"../../output/mimic_cxr/nlp_ensemble/corenlp/scoref\"\n",
    "dcoref_dir = \"../../output/mimic_cxr/nlp_ensemble/corenlp/dcoref\"\n",
    "fcoref_dir = \"../../output/mimic_cxr/nlp_ensemble/fast_coref_joint\"\n",
    "\n",
    "def batch_processing(section_name, sid, spacy_input_path):\n",
    "    START_EVENT.wait()\n",
    "    df_spacy = pd.read_csv(spacy_input_path, index_col=0, na_filter=False)\n",
    "    df_scoref = pd.read_csv(os.path.join(scoref_dir,section_name,sid+\".csv\"), index_col=0, na_filter=False)\n",
    "    df_dcoref = pd.read_csv(os.path.join(dcoref_dir,section_name,sid+\".csv\"), index_col=0, na_filter=False)\n",
    "    df_fcoref = pd.read_csv(os.path.join(fcoref_dir,section_name,sid+\".csv\"), index_col=0, na_filter=False)\n",
    "\n",
    "    token_list = df_spacy.loc[:,\"[sp]token\"].to_list()\n",
    "    token_num = len(token_list)\n",
    "\n",
    "    _, scoref_group_num = resolve_mention_and_group_num(df_scoref, \"[co][ml]coref_group_conll\")\n",
    "    _, dcoref_group_num = resolve_mention_and_group_num(df_dcoref, \"[co][rb]coref_group_conll\")\n",
    "    _, fcoref_group_num = resolve_mention_and_group_num(df_fcoref, \"[fj]coref_group_conll\")\n",
    "\n",
    "    return sid, token_num, scoref_group_num, dcoref_group_num, fcoref_group_num\n",
    "\n",
    "section_doc_numData_dict:dict[str,dict[str,dict[str,int]]] = {}\n",
    "section_scatter_data_list = {}\n",
    "for section_entry in os.scandir(\"../../output/mimic_cxr/nlp_ensemble/spacy\"):\n",
    "    if section_entry.is_dir():\n",
    "        print(\"Processing section:\", section_entry.name)\n",
    "        section_doc_numData_dict[section_entry.name]:dict[str,dict[str,int]] = {}\n",
    "\n",
    "        tasks = []\n",
    "        scatter_data_list:list[dict] = []\n",
    "        with ProcessPoolExecutor(max_workers=14) as executor:\n",
    "            for report_entry in tqdm(os.scandir(section_entry.path)):\n",
    "                if FILE_CHECKER.ignore(os.path.abspath(report_entry.path)):\n",
    "                    continue\n",
    "                sid = report_entry.name.rstrip(\".csv\")\n",
    "                tasks.append(executor.submit(batch_processing,section_entry.name, sid, report_entry.path))\n",
    "\n",
    "            START_EVENT.set()\n",
    "\n",
    "            # Receive results from multiprocessing.\n",
    "            for future in tqdm(as_completed(tasks), total=len(tasks)):\n",
    "                sid, token_num, scoref_group_num, dcoref_group_num, fcoref_group_num = future.result()\n",
    "                numData = {\n",
    "                    \"tokNum\":token_num,\n",
    "                    \"sNum\": scoref_group_num,\n",
    "                    \"dNum\": dcoref_group_num,\n",
    "                    \"fNum\": fcoref_group_num,\n",
    "                    \"avgNum\": (scoref_group_num + dcoref_group_num + fcoref_group_num) / 3\n",
    "                }\n",
    "                # For later statistic\n",
    "                section_doc_numData_dict[section_entry.name][sid]:dict[str,int] = numData\n",
    "                # For scatter plot\n",
    "                scatter_data_list.append(numData)\n",
    "\n",
    "            START_EVENT.clear()\n",
    "\n",
    "        section_scatter_data_list[section_entry.name] = scatter_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for section_name, scatter_data_list in section_scatter_data_list.items():\n",
    "\n",
    "    scatter_data_list = sorted(scatter_data_list, key=lambda x: x[\"tokNum\"]) # Sort by token num\n",
    "\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=True, sharey=True, figsize=(9,7))\n",
    "    fig.suptitle(f\"Section: {section_name}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    ax1.scatter([data_dict[\"tokNum\"] for data_dict in scatter_data_list], [data_dict[\"sNum\"] for data_dict in scatter_data_list],s=1, alpha=0.5)\n",
    "    ax2.scatter([data_dict[\"tokNum\"] for data_dict in scatter_data_list], [data_dict[\"dNum\"] for data_dict in scatter_data_list],s=1, alpha=0.5)\n",
    "    ax3.scatter([data_dict[\"tokNum\"] for data_dict in scatter_data_list], [data_dict[\"fNum\"] for data_dict in scatter_data_list],s=1, alpha=0.5)\n",
    "    ax4.scatter([data_dict[\"tokNum\"] for data_dict in scatter_data_list], [data_dict[\"avgNum\"] for data_dict in scatter_data_list],s=1, alpha=0.5)\n",
    "\n",
    "    ax1.set_title(\"ML-based\")\n",
    "    ax2.set_title(\"Rule-based\")\n",
    "    ax3.set_title(\"Neural-based\")\n",
    "    ax4.set_title(\"Unweighted mean\")\n",
    "    ax2.set_ylabel(\"Number of coreference\", fontdict={\"size\":14})\n",
    "    ax4.set_xlabel(\"Number of tokens\", fontdict={\"size\":14})\n",
    "    fig.tight_layout()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bar charts of \"number of coreference on average in the scale of token numbers\" for each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_tokRange_corefRange_docList_dict:dict[str,dict] = {}\n",
    "for section_name, doc_numData_dict in section_doc_numData_dict.items():\n",
    "    section_tokRange_corefRange_docList_dict[section_name] = {\n",
    "        \"0-49toks\": {\n",
    "            \"0coref\":[], \"0-1coref\":[], \"1coref\":[], \"1-2coref\":[], \"2coref\":[], \">2coref\":[]\n",
    "        },\n",
    "        \"50-99toks\": {\n",
    "            \"0coref\":[], \"0-1coref\":[], \"1coref\":[], \"1-2coref\":[], \"2coref\":[], \">2coref\":[]\n",
    "        },\n",
    "        \"100-149toks\": {\n",
    "            \"0coref\":[], \"0-1coref\":[], \"1coref\":[], \"1-2coref\":[], \"2coref\":[], \">2coref\":[]\n",
    "        },\n",
    "        \">150toks\": {\n",
    "            \"0coref\":[], \"0-1coref\":[], \"1coref\":[], \"1-2coref\":[], \"2coref\":[], \">2coref\":[]\n",
    "        },\n",
    "    }\n",
    "    tokRange_corefRange_docList_dict = section_tokRange_corefRange_docList_dict[section_name]\n",
    "    for doc_id, numData_dict in doc_numData_dict.items():\n",
    "        if 0 <= numData_dict[\"tokNum\"] < 50:\n",
    "            target_dict = tokRange_corefRange_docList_dict[\"0-49toks\"]\n",
    "            if numData_dict[\"avgNum\"] == 0:\n",
    "                target_dict[\"0coref\"].append(doc_id)\n",
    "            elif 0 < numData_dict[\"avgNum\"] < 1:\n",
    "                target_dict[\"0-1coref\"].append(doc_id)\n",
    "            elif numData_dict[\"avgNum\"] == 1:\n",
    "                target_dict[\"1coref\"].append(doc_id)\n",
    "            elif 1 < numData_dict[\"avgNum\"] < 2:\n",
    "                target_dict[\"1-2coref\"].append(doc_id)\n",
    "            elif numData_dict[\"avgNum\"] == 2:\n",
    "                target_dict[\"2coref\"].append(doc_id)\n",
    "            else:\n",
    "                target_dict[\">2coref\"].append(doc_id)\n",
    "        elif 50 <= numData_dict[\"tokNum\"] < 99:\n",
    "            target_dict = tokRange_corefRange_docList_dict[\"50-99toks\"]\n",
    "            if numData_dict[\"avgNum\"] == 0:\n",
    "                target_dict[\"0coref\"].append(doc_id)\n",
    "            elif 0 < numData_dict[\"avgNum\"] < 1:\n",
    "                target_dict[\"0-1coref\"].append(doc_id)\n",
    "            elif numData_dict[\"avgNum\"] == 1:\n",
    "                target_dict[\"1coref\"].append(doc_id)\n",
    "            elif 1 < numData_dict[\"avgNum\"] < 2:\n",
    "                target_dict[\"1-2coref\"].append(doc_id)\n",
    "            elif numData_dict[\"avgNum\"] == 2:\n",
    "                target_dict[\"2coref\"].append(doc_id)\n",
    "            else:\n",
    "                target_dict[\">2coref\"].append(doc_id)\n",
    "        elif 100 <= numData_dict[\"tokNum\"] < 149:\n",
    "            target_dict = tokRange_corefRange_docList_dict[\"100-149toks\"]\n",
    "            if numData_dict[\"avgNum\"] == 0:\n",
    "                target_dict[\"0coref\"].append(doc_id)\n",
    "            elif 0 < numData_dict[\"avgNum\"] < 1:\n",
    "                target_dict[\"0-1coref\"].append(doc_id)\n",
    "            elif numData_dict[\"avgNum\"] == 1:\n",
    "                target_dict[\"1coref\"].append(doc_id)\n",
    "            elif 1 < numData_dict[\"avgNum\"] < 2:\n",
    "                target_dict[\"1-2coref\"].append(doc_id)\n",
    "            elif numData_dict[\"avgNum\"] == 2:\n",
    "                target_dict[\"2coref\"].append(doc_id)\n",
    "            else:\n",
    "                target_dict[\">2coref\"].append(doc_id)\n",
    "        elif numData_dict[\"tokNum\"] >= 150:\n",
    "            target_dict = tokRange_corefRange_docList_dict[\">150toks\"]\n",
    "            if numData_dict[\"avgNum\"] == 0:\n",
    "                target_dict[\"0coref\"].append(doc_id)\n",
    "            elif 0 < numData_dict[\"avgNum\"] < 1:\n",
    "                target_dict[\"0-1coref\"].append(doc_id)\n",
    "            elif numData_dict[\"avgNum\"] == 1:\n",
    "                target_dict[\"1coref\"].append(doc_id)\n",
    "            elif 1 < numData_dict[\"avgNum\"] < 2:\n",
    "                target_dict[\"1-2coref\"].append(doc_id)\n",
    "            elif numData_dict[\"avgNum\"] == 2:\n",
    "                target_dict[\"2coref\"].append(doc_id)\n",
    "            else:\n",
    "                target_dict[\">2coref\"].append(doc_id)\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(9,7))\n",
    "    fig.suptitle(f\"Section: {section_name}\")\n",
    "\n",
    "    for ax_id, (tokRangeLabel, corefRangeDict) in enumerate(tokRange_corefRange_docList_dict.items()):\n",
    "        x = corefRangeDict.keys()\n",
    "        y = [len(_sid_list) for _sid_list in corefRangeDict.values()]\n",
    "        bar_container = axs[ax_id].bar(x,y)\n",
    "        axs[ax_id].set_title(tokRangeLabel)\n",
    "        axs[ax_id].bar_label(bar_container, padding=3)\n",
    "\n",
    "    axs[1].set_ylabel(\"Number of notes (reports)\")\n",
    "    axs[3].set_xlabel(\"Coreference Range\")\n",
    "    \n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include 0 coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for section_name, tokRange_corefRange_docList_dict in section_tokRange_corefRange_docList_dict.items():\n",
    "    data_list:list[list] = []\n",
    "    for tokRange, corefRange_docList_dict in tokRange_corefRange_docList_dict.items():\n",
    "        data_row = []\n",
    "        data_list.append(data_row)\n",
    "        for corefRange, docList in corefRange_docList_dict.items():\n",
    "            data_row.append(len(docList))\n",
    "    data = np.array(data_list)\n",
    "    percentages = data/data.sum() * 100\n",
    "\n",
    "    new_row = []\n",
    "    for col_idx in range(len(percentages[0])):\n",
    "        new_row.append(percentages[:,col_idx].sum())\n",
    "    new_percentages = np.append(percentages, [new_row], 0)\n",
    "\n",
    "    new_col = []\n",
    "    for row_idx in range(len(new_percentages)):\n",
    "        new_col.append([new_percentages[row_idx].sum()])\n",
    "    new_percentages = np.append(new_percentages, new_col, 1)\n",
    "\n",
    "    x_labels = [\"0\", \"0-1\", \"1\", \"1-2\", \"2\", \">2\", \"all\"]\n",
    "    y_labels = [\"0-49\",\"50-99\", \"100-149\", \">150\", \"all\"]\n",
    "\n",
    "    plt.figure() #this creates a new figure on which your plot will appear\n",
    "    plt.title(f\"Section: {section_name}, total: {data.sum()}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = sns.heatmap(new_percentages, xticklabels=x_labels, yticklabels=y_labels, annot=True, fmt='.2f')\n",
    "    ax.set_xlabel(\"Number of coreferences\")\n",
    "    ax.set_ylabel(\"Number of tokens\")\n",
    "\n",
    "print(\"Each value shown in a cell is percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclude 0 coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for section_name, tokRange_corefRange_docList_dict in section_tokRange_corefRange_docList_dict.items():\n",
    "    data_list:list[list] = []\n",
    "    for tokRange, corefRange_docList_dict in tokRange_corefRange_docList_dict.items():\n",
    "        data_row = []\n",
    "        data_list.append(data_row)\n",
    "        for corefRange, docList in corefRange_docList_dict.items():\n",
    "            if corefRange == \"0coref\":\n",
    "                continue\n",
    "            data_row.append(len(docList))\n",
    "    data = np.array(data_list)\n",
    "    percentages = data/data.sum() * 100\n",
    "\n",
    "    # add overall statistic\n",
    "    new_row = []\n",
    "    for col_idx in range(len(percentages[0])):\n",
    "        new_row.append(percentages[:,col_idx].sum())\n",
    "    new_percentages = np.append(percentages, [new_row], 0)\n",
    "\n",
    "    new_col = []\n",
    "    for row_idx in range(len(new_percentages)):\n",
    "        new_col.append([new_percentages[row_idx].sum()])\n",
    "    new_percentages = np.append(new_percentages, new_col, 1)\n",
    "\n",
    "    x_labels = [\"0-1\", \"1\", \"1-2\", \"2\", \">2\", \"all\"]\n",
    "    y_labels = [\"0-49\",\"50-99\", \"100-149\", \">150\", \"all\"]\n",
    "\n",
    "    plt.figure() #this creates a new figure on which your plot will appear\n",
    "    plt.title(f\"Section: {section_name}, total: {data.sum()}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = sns.heatmap(new_percentages, xticklabels=x_labels, yticklabels=y_labels, annot=True, fmt='.2f')\n",
    "    ax.set_xlabel(\"Number of coreferences\")\n",
    "    ax.set_ylabel(\"Number of tokens\")\n",
    "\n",
    "print(\"Each value shown in a cell is percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "\n",
    "new_row = []\n",
    "for col_idx in range(len(data[0])):\n",
    "    new_row.append(data[:,col_idx].sum())\n",
    "\n",
    "new_data = np.append(data, [new_row], 0)\n",
    "\n",
    "\n",
    "new_col = []\n",
    "for row_idx in range(len(new_data)):\n",
    "    new_col.append([new_data[row_idx].sum()])\n",
    "\n",
    "new_data = np.append(new_data, new_col, 1)\n",
    "\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling with out ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = section_tokRange_corefRange_docList_dict[\"findings\"][\"100-149toks\"][\"1coref\"][0]\n",
    "section_name = \"findings\"\n",
    "print(\"section_name, doc_id:\",section_name, doc_id)\n",
    "\n",
    "df_scoref = pd.read_csv(os.path.join(scoref_dir,section_name,f\"{doc_id}.csv\"), index_col=0, na_filter=False)\n",
    "df_dcoref = pd.read_csv(os.path.join(dcoref_dir,section_name,f\"{doc_id}.csv\"), index_col=0, na_filter=False)\n",
    "df_fcoref = pd.read_csv(os.path.join(fcoref_dir,section_name,f\"{doc_id}.csv\"), index_col=0, na_filter=False)\n",
    "\n",
    "\n",
    "_, scoref_group_num = resolve_mention_and_group_num(df_scoref, \"[co][ml]coref_group_conll\")\n",
    "_, dcoref_group_num = resolve_mention_and_group_num(df_dcoref, \"[co][rb]coref_group_conll\")\n",
    "_, fcoref_group_num = resolve_mention_and_group_num(df_fcoref, \"[fj]coref_group_conll\")\n",
    "\n",
    "print(\"scoref_group_num, dcoref_group_num, fcoref_group_num:\", scoref_group_num, dcoref_group_num, fcoref_group_num)\n",
    "print(section_list[0][1][sid_list.index(doc_id)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "sampling_num_dict = {\n",
    "    \"findings\": [\n",
    "        [2,3,2,1,1,1],\n",
    "        [7,5,5,4,1,1],\n",
    "        [3,2,2,2,1,1],\n",
    "        [1,1,1,1,1,1]\n",
    "    ],\n",
    "        \"impression\": [\n",
    "        [4,3,2,1,1,1],\n",
    "        [6,5,5,4,1,1],\n",
    "        [2,2,2,2,1,1],\n",
    "        [1,1,1,1,1,1]\n",
    "    ]\n",
    "}\n",
    "output_section_doc_dict = {}\n",
    "for section_name, tokRange_corefRange_docList_dict in section_tokRange_corefRange_docList_dict.items():\n",
    "    if section_name not in sampling_num_dict:\n",
    "        continue\n",
    "    output_section_doc_dict[section_name] = []\n",
    "    for x_idx,(tokRange, corefRange_docList_dict) in enumerate(tokRange_corefRange_docList_dict.items()):\n",
    "        for y_idx, (corefRange, docList) in enumerate(corefRange_docList_dict.items()):\n",
    "            docList = sorted(docList)\n",
    "            required_num = sampling_num_dict[section_name][x_idx][y_idx]\n",
    "            sampled_doc = [docList[random.randint(0,len(docList)-1)] for _ in range(required_num)]\n",
    "            output_section_doc_dict[section_name].extend(sampled_doc)\n",
    "            print(section_name, tokRange, corefRange, sampled_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from common_utils.common_utils import check_and_remove_dirs\n",
    "\n",
    "check_and_remove_dirs(\"../../output/mimic_cxr/statistic/for_brat_annotation\", True)\n",
    "for section_name, _doc_list in output_section_doc_dict.items():\n",
    "    output_dir = os.path.join(\"../../output/mimic_cxr/statistic/for_brat_annotation\",section_name)\n",
    "    check_and_create_dirs(output_dir)\n",
    "    input_dir = os.path.join(\"../../output/mimic_cxr/nlp_ensemble/spacy\",section_name)\n",
    "    for doc_id in tqdm(_doc_list):\n",
    "        df_spacy = pd.read_csv(os.path.join(input_dir, f\"{doc_id}.csv\"), index_col=0, na_filter=False)\n",
    "        df_sentence = df_spacy.groupby(['[sp]sentence_group'])['[sp]token'].apply(' '.join).reset_index()\n",
    "        sentences = [str(_series.get(\"[sp]token\")).strip() for _, _series in df_sentence.iterrows()]\n",
    "        with open(os.path.join(output_dir, f\"{doc_id}.txt\"), \"w\", encoding=\"UTF-8\") as f:\n",
    "            f.write(\"\\n\".join(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling with ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156011/156011 [00:03<00:00, 43962.40it/s]\n",
      "100%|██████████| 156011/156011 [00:39<00:00, 3917.51it/s]\n",
      "100%|██████████| 189465/189465 [00:04<00:00, 40970.63it/s]\n",
      "100%|██████████| 189465/189465 [00:47<00:00, 4004.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "from common_utils.coref_utils import get_file_name_prefix\n",
    "\n",
    "\n",
    "coref_group_conll_colName = \"[fj]coref_group_conll\"\n",
    "input_base_dir = \"../../output/mimic_cxr/nlp_ensemble/fast_coref_onto_i2b2\"\n",
    "\n",
    "def batch_processing2(file_name, input_file_path):\n",
    "    START_EVENT.wait()\n",
    "    doc_id = get_file_name_prefix(input_file_path, \".csv\")\n",
    "    df = pd.read_csv(input_file_path, index_col=0, na_filter=False)\n",
    "    _, coref_group_num = resolve_mention_and_group_num(df, coref_group_conll_colName, omit_singleton=True)\n",
    "    return doc_id, coref_group_num\n",
    "\n",
    "section_doc_coref_counter = defaultdict(Counter)\n",
    "all_section_corefGroupNum_docId_dict = {}\n",
    "for section_name in [\"findings\", \"impression\"]:\n",
    "    with ProcessPoolExecutor(max_workers=15) as executor:\n",
    "        all_task = []\n",
    "        input_dir = os.path.join(input_base_dir, section_name)\n",
    "        for file_name in tqdm(FILE_CHECKER.filter(os.listdir(input_dir))):\n",
    "            input_file_path = os.path.join(input_dir, file_name)\n",
    "            all_task.append(executor.submit(batch_processing2, file_name, input_file_path))\n",
    "\n",
    "        # Notify tasks to start\n",
    "        START_EVENT.set()\n",
    "\n",
    "        corefGroupNum_docId_dict = defaultdict(list)\n",
    "        if all_task:\n",
    "            for future in tqdm(as_completed(all_task), total=len(all_task)):\n",
    "                doc_id, coref_group_num = future.result()\n",
    "                section_doc_coref_counter[section_name].update([coref_group_num])\n",
    "                corefGroupNum_docId_dict[coref_group_num].append(doc_id)\n",
    "                \n",
    "        all_section_corefGroupNum_docId_dict[section_name] = corefGroupNum_docId_dict\n",
    "        executor.shutdown(wait=True, cancel_futures=False)\n",
    "        START_EVENT.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of gt doc\n",
    "gt_source_list = [\n",
    "    \"../../output/mimic_cxr/ground_truth\",\n",
    "    \"../../output/mimic_cxr/coref_voting/majority_voting_sampling1\"\n",
    "]\n",
    "gt_section_docId_dict:dict[str,list] = {}\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    for source_dir in gt_source_list:\n",
    "        gt_all_dir = os.path.join(source_dir, section_name)\n",
    "        gt_section_docId_dict.setdefault(section_name,[]).extend([i.rstrip(\".csv\") for i in FILE_CHECKER.filter(os.listdir(gt_all_dir))])\n",
    "    \n",
    "# The coref distribution (majority_voting version) of the annotated gt files.\n",
    "gt_section_corefGroupNum_docId_dict = {}\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    gt_section_corefGroupNum_docId_dict[section_name] = {}\n",
    "    for coref_num, doc_id_list in all_section_corefGroupNum_docId_dict[section_name].items():\n",
    "        gt_section_corefGroupNum_docId_dict[section_name][coref_num] = []\n",
    "        for doc_id in gt_section_docId_dict[section_name]:\n",
    "            if doc_id in doc_id_list:\n",
    "                gt_section_corefGroupNum_docId_dict[section_name][coref_num].append(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data distribution of all docs:\n",
      "findings [(1, 15956), (0, 136639), (2, 2624), (3, 597), (6, 12), (4, 145), (5, 37), (7, 1)]\n",
      "impression [(0, 173932), (1, 12634), (2, 2197), (3, 561), (4, 110), (5, 22), (6, 6), (7, 2), (8, 1)]\n",
      "\n",
      "The data distribution of test docs (docs that had been selected for annotation):\n",
      "findings [(1, 43), (0, 25), (2, 22), (3, 7), (6, 0), (4, 2), (5, 1), (7, 0)]\n",
      "impression [(0, 26), (1, 41), (2, 21), (3, 8), (4, 2), (5, 2), (6, 0), (7, 0), (8, 0)]\n",
      "\n",
      "The data distribution of all docs excluding test docs\n",
      "findings [(1, 15913), (0, 136614), (2, 2602), (3, 590), (6, 12), (4, 143), (5, 36), (7, 1)]\n",
      "impression [(0, 173906), (1, 12593), (2, 2176), (3, 553), (4, 108), (5, 20), (6, 6), (7, 2), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(\"The data distribution of all docs:\")\n",
    "for section_name, corefGroupNum_docId_dict in all_section_corefGroupNum_docId_dict.items():\n",
    "    print(section_name, [(coref_num, len(doc_id_list)) for coref_num, doc_id_list in corefGroupNum_docId_dict.items()])\n",
    "\n",
    "print(\"\\nThe data distribution of test docs (docs that had been selected for annotation):\")\n",
    "for section_name, corefGroupNum_docId_dict in gt_section_corefGroupNum_docId_dict.items():\n",
    "    print(section_name, [(coref_num, len(doc_id_list)) for coref_num, doc_id_list in corefGroupNum_docId_dict.items()])\n",
    "\n",
    "print(\"\\nThe data distribution of all docs excluding test docs\")\n",
    "for section_name, corefGroupNum_docId_dict in all_section_corefGroupNum_docId_dict.items():\n",
    "    print(section_name, [(coref_num, len(doc_id_list)-len(gt_section_corefGroupNum_docId_dict[section_name][coref_num])) for coref_num, doc_id_list in corefGroupNum_docId_dict.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design the sampling distribution for next round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_corefGroupNum_sampleDocNum_dict = {\n",
    "    \"findings\": {1: 20, 2: 20, 3: 7, 4: 2, 5: 1},\n",
    "    \"impression\": {1: 20, 2: 20, 3: 7, 4: 2, 5: 1}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the target doc_ids for a new annotation procedure (also perform majority voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from nlp_ensemble.nlp_menbers import play_fastcoref\n",
    "\n",
    "config = None\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"create_ann\"):\n",
    "        config = compose(config_name=\"coreference_resolution\", overrides=[\"+coreference_resolution/coref_voting@_global_=mimic_cxr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.09s/it]\n",
      "100%|██████████| 50/50 [00:48<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from common_utils.coref_utils import shuffle_list\n",
    "import coref_voting\n",
    "from coref_voting import DocClass, MentionClass, compute_voting_result, get_output_df\n",
    "\n",
    "mv_output_base_dir = os.path.join(\"../../output/mimic_cxr/coref_voting/majority_voting_sampling2\")\n",
    "\n",
    "def batch_processing3(config, spacy_file_path, section_name, file_name):\n",
    "    \"\"\" Voting on one document \"\"\"\n",
    "\n",
    "    START_EVENT.wait()\n",
    "\n",
    "    # Read spacy output as alignment base\n",
    "    df_spacy = pd.read_csv(spacy_file_path, index_col=0, na_filter=False)\n",
    "    # Some of the i2b2 raw files are utf-8 start with DOM, but we didn't remove the DOM character, thus we fix it here.\n",
    "    df_spacy.iloc[0] = df_spacy.iloc[0].apply(lambda x: x.replace(\"\\ufeff\", \"\").replace(\"\\xef\\xbb\\xbf\", \"\") if isinstance(x, str) else x)\n",
    "\n",
    "    docObj: DocClass = coref_voting.resolve_voting_info(config, df_spacy, section_name, file_name)\n",
    "    valid_mention_group: list[set[MentionClass]] = compute_voting_result(config, docObj)\n",
    "    df_out = get_output_df(config, df_spacy, valid_mention_group, docObj)\n",
    "\n",
    "    output_dir = os.path.join(mv_output_base_dir, section_name)\n",
    "    check_and_create_dirs(output_dir)\n",
    "    output_file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    df_out.to_csv(output_file_path)\n",
    "\n",
    "    return f\"{file_name} done.\"\n",
    "\n",
    "for section_name, corefGroupNum_sampleDocNum_dict in section_corefGroupNum_sampleDocNum_dict.items():\n",
    "    # sample_num_str = \"{1: 544, 2: 544, 3: 295, 4: 83, 5: 25, 6: 6, 7: 2, 8: 1}\"\n",
    "    with ProcessPoolExecutor(max_workers=config.thread.workers) as executor:\n",
    "        all_task = []\n",
    "        for groupNum, sampleDocNum in corefGroupNum_sampleDocNum_dict.items():\n",
    "            # Get the acutal doc ids. Remove the doc_ids that used in testset. Then shuffle.\n",
    "            docId_all_list = all_section_corefGroupNum_docId_dict[section_name][groupNum]\n",
    "            docId_exclude_list = gt_section_corefGroupNum_docId_dict[section_name][groupNum]\n",
    "            docId_list_excluded = [x for x in docId_all_list if x not in docId_exclude_list]\n",
    "            docId_list_shuffle = shuffle_list(docId_list_excluded, 42)\n",
    "            \n",
    "            for doc_id in docId_list_shuffle[0:sampleDocNum]:\n",
    "                file_name = doc_id + \".csv\"\n",
    "                spacy_out_dir = os.path.join(config.input.source.baseline_model.dir, section_name)\n",
    "                spacy_file_path = os.path.join(spacy_out_dir, file_name)\n",
    "                all_task.append(executor.submit(batch_processing3, config, spacy_file_path, section_name, file_name))\n",
    "        \n",
    "         # Notify tasks to start\n",
    "        START_EVENT.set()\n",
    "\n",
    "        if all_task:\n",
    "            for future in tqdm(as_completed(all_task), total=len(all_task)):\n",
    "                msg = future.result()\n",
    "\n",
    "        executor.shutdown(wait=True, cancel_futures=False)\n",
    "        START_EVENT.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnMentionClass:\n",
    "    def __init__(self) -> None:\n",
    "        self.id = \"\"\n",
    "        self.type = \"Mention\"\n",
    "        self.start_index = \"\"\n",
    "        self.end_index = \"\"\n",
    "        self.token_str_list = []\n",
    "        self.token_str = \"\"\n",
    "    \n",
    "    def get_ann_str(self) -> str:\n",
    "        return f\"{self.id}\\t{self.type} {self.start_index} {self.end_index}\\t{' '.join(self.token_str_list)}\\n\"\n",
    "\n",
    "    def set_end_index(self, value, text):\n",
    "        self.end_index = value\n",
    "        self.token_str = text[self.start_index:self.end_index]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.get_ann_str()\n",
    "    def __str__(self) -> str:\n",
    "        return self.get_ann_str()\n",
    "\n",
    "class AnnCoreferenceClass:\n",
    "    def __init__(self) -> None:\n",
    "        self.id = \"\"\n",
    "        self.type = \"Coreference\"\n",
    "        self.anaphora = \"\"\n",
    "        self.antecedent = \"\"\n",
    "    \n",
    "    def get_ann_str(self) -> str:\n",
    "        return f\"{self.id}\\t{self.type} Anaphora:{self.anaphora} Antecedent:{self.antecedent}\\t\\n\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.get_ann_str()\n",
    "    def __str__(self) -> str:\n",
    "        return self.get_ann_str()\n",
    "\n",
    "\n",
    "def get_AnnMentionClass_notClosed(ann_ment_list: list[AnnMentionClass]) -> AnnMentionClass:\n",
    "    for annMent in ann_ment_list:\n",
    "        if annMent.end_index == \"\":\n",
    "            return annMent\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "brat_output_dir = os.path.join(\"../../output/mimic_cxr/brat_annotation_original/round3\")\n",
    "\n",
    "for section_name in [\"findings\", \"impression\"]:\n",
    "    input_dir = os.path.join(mv_output_base_dir, section_name)\n",
    "\n",
    "    for doc_id in [i.rstrip(\".csv\") for i in FILE_CHECKER.filter(os.listdir(input_dir))]:\n",
    "        df_spacy = pd.read_csv(os.path.join(input_dir, f\"{doc_id}.csv\"), index_col=0, na_filter=False)\n",
    "        df_sentence = df_spacy.groupby(['[sp]sentence_group'])['[sp]token'].apply('#@#'.join).reset_index()\n",
    "        df_coref = df_spacy.groupby(['[sp]sentence_group'])[\"[mv]coref_group_conll\"].apply(list).reset_index()\n",
    "\n",
    "        sentences = [str(_series.get(\"[sp]token\")).replace(\"#@#\",\" \").strip() for _, _series in df_sentence.iterrows()]\n",
    "        text = \"\\n\".join(sentences)\n",
    "        # .txt files\n",
    "        output_dir = os.path.join(brat_output_dir, section_name)\n",
    "        check_and_create_dirs(output_dir)\n",
    "        with open(os.path.join(output_dir, f\"{doc_id}.txt\"), \"w\", encoding=\"UTF-8\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "        # .ann files\n",
    "        with open(os.path.join(output_dir, f\"{doc_id}.ann\"), \"w\", encoding=\"UTF-8\") as f:\n",
    "            mention_id = 0\n",
    "            groupNum_mentions_dict:dict[int, list[AnnMentionClass]] = defaultdict(list)\n",
    "            offset = 0\n",
    "            for _idx, _series in df_sentence.iterrows():\n",
    "                token_list = _series.get('[sp]token').strip().strip(\"#@#\").split('#@#') # Remove the last whitespace\n",
    "                conll_labelStr_list = df_coref.loc[_idx,].get(\"[mv]coref_group_conll\") # The corresponding conll label of last whitespace are reamined so far\n",
    "                \n",
    "                for tok_id, tok in enumerate(token_list): # The corresponding conll label of last whitespace will be ignored \n",
    "                    conll_labelListStr = conll_labelStr_list[tok_id]\n",
    "                    if conll_labelListStr not in [-1, \"-1\", np.nan]:\n",
    "                        for conll_label in ast.literal_eval(conll_labelListStr):\n",
    "                            if \"(\" in conll_label:\n",
    "                                ann_mention_class = AnnMentionClass()\n",
    "                                ann_mention_class.id = f\"T{mention_id}\"\n",
    "                                ann_mention_class.start_index = offset\n",
    "                                mention_id+=1\n",
    "                                if \")\" in conll_label:\n",
    "                                    ann_mention_class.set_end_index(offset + len(tok), \"\\n\".join(sentences))\n",
    "                                    coref_id = int(conll_label.replace(\"(\",\"\").replace(\")\",\"\"))\n",
    "                                else:\n",
    "                                    coref_id = int(conll_label.replace(\"(\",\"\"))\n",
    "                                groupNum_mentions_dict[coref_id].append(ann_mention_class)\n",
    "                            elif \"(\" not in conll_label and \")\" in conll_label:\n",
    "                                coref_id = int(conll_label.replace(\")\",\"\"))\n",
    "                                ann_mention_class = get_AnnMentionClass_notClosed(groupNum_mentions_dict[coref_id])\n",
    "                                ann_mention_class.set_end_index(offset + len(tok), \"\\n\".join(sentences))\n",
    "\n",
    "                    offset += len(tok) + 1\n",
    "                offset = sum([len(sent) for sent in sentences[0:_idx+1]]) + _idx + 1 # The offset of the sentence start.\n",
    "\n",
    "            pair_id = 0\n",
    "            for _, ann_mention_list in groupNum_mentions_dict.items():\n",
    "                for _id, ann_mention_class in enumerate(ann_mention_list):\n",
    "                    f.write(ann_mention_class.get_ann_str())\n",
    "\n",
    "                for _id, ann_mention_class in enumerate(ann_mention_list):\n",
    "                    if _id == 0:\n",
    "                        continue\n",
    "                    ann_coref_class = AnnCoreferenceClass()\n",
    "                    ann_coref_class.id = f\"R{pair_id}\"\n",
    "                    ann_coref_class.anaphora = ann_mention_list[_id-1].id\n",
    "                    ann_coref_class.antecedent = ann_mention_list[_id].id\n",
    "\n",
    "                    f.write(ann_coref_class.get_ann_str())\n",
    "                    pair_id += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('corenlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb6968a69f778f9e728e35b65cd79a0dbef5b20465434381676f63f710dc4a24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
