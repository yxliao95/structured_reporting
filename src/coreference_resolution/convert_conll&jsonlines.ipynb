{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# From csv to conll / jsonlines\n",
                "\n",
                "For the eval.ipynb, we need to get individual conll files for evaulation\n",
                "1. Run `Prepare` and `Step 1`\n",
                "\n",
                "For training fast-coref model\n",
                "1. Run `Prepare`\n",
                "2. Run `Step 1 & 2 & 3`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prepare"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append(\"../../src\")\n",
                "sys.path.append(\"../../../../git_clone_repos/fast-coref/src/\")\n",
                "\n",
                "import os\n",
                "from tqdm import tqdm\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib as mpl\n",
                "import json\n",
                "import logging\n",
                "\n",
                "from IPython.display import display, HTML\n",
                "# display(HTML(df.to_html()))\n",
                "\n",
                "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
                "from multiprocessing import Event\n",
                "from common_utils.data_loader_utils import load_mimic_cxr_bySection\n",
                "from common_utils.coref_utils import resolve_mention_and_group_num\n",
                "from common_utils.file_checker import FileChecker\n",
                "from common_utils.common_utils import check_and_create_dirs, check_and_remove_dirs\n",
                "from data_preprocessing import mimic_cxr_csv2conll, mimic_cxr_conll2jsonlines\n",
                "\n",
                "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
                "\n",
                "FILE_CHECKER = FileChecker()\n",
                "START_EVENT = Event()\n",
                "logger = logging.getLogger()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from hydra import compose, initialize\n",
                "from omegaconf import OmegaConf\n",
                "\n",
                "config = None\n",
                "with initialize(version_base=None, config_path=\"../config\", job_name=\"coreference_resolution\"):\n",
                "        config = compose(config_name=\"coreference_resolution\", overrides=[\"+coreference_resolution/data_preprocessing@_global_=mimic_cxr\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Generate individual conll files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Source input dir (csv)\n",
                "config.input_gt.base_dir = \"../../output/mimic_cxr/manual_training_set/round4_500_1234r3\"\n",
                "# Target output dir (conll)\n",
                "config.temp_gt.base_dir = \"../../output/mimic_cxr/coref/individual_conll_ground_truth/round4_500_1234r3\"\n",
                "config.temp_gt.force_run = False # Force to delete and recreate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Individual test conll files found and will be reused.\n"
                    ]
                }
            ],
            "source": [
                "check_and_remove_dirs(config.temp_gt.base_dir, config.temp_gt.force_run)\n",
                "if os.path.exists(config.temp_gt.base_dir):\n",
                "    print(\"Individual test conll files found and will be reused.\")\n",
                "else:\n",
                "    log_out = mimic_cxr_csv2conll.prepare_conll(config, config.input_gt, config.temp_gt)\n",
                "    with open(config.output.run_statistic, \"a\", encoding=\"UTF-8\") as f:\n",
                "        f.write(f\"Source: {config.temp_gt.base_dir} \\n\")\n",
                "        f.write(json.dumps(log_out, indent=2))\n",
                "        f.write(\"\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Generate aggregrated conll files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "config.data_split.activate = [\"train_manual\", \"test_gt\"]\n",
                "\n",
                " # The docs in `target_doc_dir` dir is the docs we want to get from the `source_dir`\n",
                "config.data_split.train_manual.target_doc_dir = config.input_gt.base_dir # csv file path\n",
                "config.data_split.train_manual.source_dir = config.temp_gt.base_dir # Individual conll file path\n",
                "\n",
                "# config.data_split.test_gt.target_doc_dir = \"../../output/mimic_cxr/manual_test_set/round1x2\" \n",
                "# config.data_split.test_gt.source_dir = \"../../output/mimic_cxr/coref/individual_conll_ground_truth/round1x2\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "log_out = mimic_cxr_csv2conll.aggregrate_conll(config)\n",
                "with open(config.output.log_file, \"a\", encoding=\"UTF-8\") as f:\n",
                "    for split_mode, details in log_out.items():\n",
                "        f.write(json.dumps({\n",
                "            \"output_folder\": split_mode,\n",
                "            \"details\": details\n",
                "        }, indent=2))\n",
                "        f.write(\"\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Generage jsonlines files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "config.longformer.source = [{'train': 'train_manual'}, {'dev': 'train_manual'}, {'test': 'test_gt'}]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: longformer, Segment length: 4096\n"
                    ]
                }
            ],
            "source": [
                "log_msg = mimic_cxr_conll2jsonlines.invoke(config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['Wrote 371 documents to /home/yuxiangliao/PhD/workspace/VSCode_workspace/structured_reporting/output/mimic_cxr/coref/longformer/train.4096.jsonlines',\n",
                            " 'Wrote 94 documents to /home/yuxiangliao/PhD/workspace/VSCode_workspace/structured_reporting/output/mimic_cxr/coref/longformer/dev.4096.jsonlines',\n",
                            " 'Wrote 156 documents to /home/yuxiangliao/PhD/workspace/VSCode_workspace/structured_reporting/output/mimic_cxr/coref/longformer/test.4096.jsonlines']"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "log_msg"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.12 ('corenlp')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "bb6968a69f778f9e728e35b65cd79a0dbef5b20465434381676f63f710dc4a24"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
