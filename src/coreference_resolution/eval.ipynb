{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on MIMIC-CXR manual annotation\n",
    "\n",
    "We have 100 maunally annotated documents as ground-truth/testset, of which 64 docs have coref while the others are 0-coref.\n",
    "\n",
    "The individual ground-truth conll files are saved in \"/individual_conll_ground_truth\".\n",
    "\n",
    "To evaluate, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"../../../../git_clone_repos/fast-coref/src\")\n",
    "\n",
    "import os\n",
    "import ast\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from IPython.display import display, HTML\n",
    "from common_utils.coref_utils import ConllToken\n",
    "# display(HTML(df.to_html()))\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from multiprocessing import Event\n",
    "from common_utils.data_loader_utils import load_mimic_cxr_bySection\n",
    "from common_utils.coref_utils import resolve_mention_and_group_num\n",
    "from common_utils.file_checker import FileChecker\n",
    "from common_utils.common_utils import check_and_create_dirs, check_and_remove_dirs, check_and_remove_file\n",
    "from coreference_resolution.data_preprocessing.mimic_cxr_csv2conll import copy_and_paste_conll\n",
    "from statistic.coref_socring import invoke_conll_script, resolve_conll_script_output\n",
    "\n",
    "FILE_CHECKER = FileChecker()\n",
    "START_EVENT = Event()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conll_score(conll_file_gt, conll_file_pred):\n",
    "    print(\"gt:\", conll_file_gt)\n",
    "    print(\"pred:\", conll_file_pred)\n",
    "    scorer_path = \"./wrong_conll_scorer_example/reference-coreference-scorers/scorer.pl\"\n",
    "    overall_f1 = []\n",
    "    for metric in ['muc', 'bcub', 'ceafe']:\n",
    "        out, err = invoke_conll_script(scorer_path, metric, conll_file_gt, conll_file_pred)\n",
    "        mention_recall, mention_precision, mention_f1, coref_recall, coref_precision, coref_f1 = resolve_conll_script_output(out)\n",
    "        overall_f1.append(coref_f1)\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(f\"mention_recall, mention_precision, mention_f1: {mention_recall}, {mention_precision}, {mention_f1}\")\n",
    "        print(f\"coref_recall, coref_precision, coref_f1: {coref_recall}, {coref_precision}, {coref_f1}\")\n",
    "\n",
    "    print(f\"Overall F1: {sum(overall_f1) / len(overall_f1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv_to_conll(section_name, doc_id, output_file_path, input_file_path_or_df, coref_group_conll_colName, sentence_group_colName,token_colName):\n",
    "    BEGIN = f\"#begin document ({doc_id}_{section_name}); part 0\\n\"\n",
    "    SENTENCE_SEPARATOR = \"\\n\"\n",
    "    END = \"#end document\\n\"\n",
    "\n",
    "    # Resolve CSV file\n",
    "    sentenc_list: list[list[ConllToken]] = []\n",
    "    if isinstance(input_file_path_or_df, str):\n",
    "        df = pd.read_csv(input_file_path_or_df, index_col=0, na_filter=False)\n",
    "    else:\n",
    "        df = input_file_path_or_df\n",
    "\n",
    "    sentence_id = 0\n",
    "    while True:\n",
    "        token_list: list[ConllToken] = []\n",
    "        df_sentence = df[df.loc[:, sentence_group_colName] == sentence_id].reset_index()\n",
    "        if df_sentence.empty:\n",
    "            break\n",
    "        for _idx, data in df_sentence.iterrows():\n",
    "            # Skip all whitespces like \"\\n\", \"\\n \" and \" \".\n",
    "            if str(data[token_colName]).strip() == \"\":\n",
    "                continue\n",
    "            conllToken = ConllToken(doc_id+\"_\"+section_name, sentence_id, _idx, data[token_colName])\n",
    "            coref_col_cell = data[coref_group_conll_colName]\n",
    "            if isinstance(coref_col_cell, str) and coref_col_cell != \"-1\":\n",
    "                conllToken.add_coref_label(\"|\".join(ast.literal_eval(coref_col_cell)))\n",
    "            token_list.append(conllToken)\n",
    "        sentenc_list.append(token_list)\n",
    "        sentence_id += 1\n",
    "\n",
    "    with open(output_file_path, \"a\", encoding=\"UTF-8\") as out:\n",
    "        out.write(BEGIN)\n",
    "        for sent in sentenc_list:\n",
    "            # Skip empty sentence\n",
    "            if len(sent) == 1 and sent[0].tokenStr == \"\":\n",
    "                continue\n",
    "            for tok in sent:\n",
    "                out.write(tok.get_conll_str() + \"\\n\")\n",
    "            out.write(SENTENCE_SEPARATOR)\n",
    "        out.write(END)\n",
    "        out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_list_to_conll(output_file_path, doc_id, section_name, old_sentenc_list):\n",
    "    BEGIN = f\"#begin document ({doc_id}_{section_name}); part 0\\n\"\n",
    "    SENTENCE_SEPARATOR = \"\\n\"\n",
    "    END = \"#end document\\n\"\n",
    "\n",
    "    sentenc_list: list[list[ConllToken]] = []\n",
    "    for sentence_id, old_token_list in enumerate(old_sentenc_list):\n",
    "        token_list: list[ConllToken] = []\n",
    "        for tok_idx, tok in enumerate(old_token_list):\n",
    "            # Skip all whitespces like \"\\n\", \"\\n \" and \" \".\n",
    "            if tok.tokenStr.strip() == \"\":\n",
    "                continue\n",
    "            conllToken = ConllToken(doc_id+\"_\"+section_name, sentence_id, tok_idx, tok.tokenStr)\n",
    "            conllToken.corefLabel = tok.corefLabel\n",
    "            token_list.append(conllToken)\n",
    "        sentenc_list.append(token_list)\n",
    "\n",
    "    with open(output_file_path, \"a\", encoding=\"UTF-8\") as out:\n",
    "        out.write(BEGIN)\n",
    "        for sent in sentenc_list:\n",
    "            # Skip empty sentence\n",
    "            if len(sent) == 1 and sent[0].tokenStr == \"\":\n",
    "                continue\n",
    "            for tok in sent:\n",
    "                out.write(tok.get_conll_str() + \"\\n\")\n",
    "            out.write(SENTENCE_SEPARATOR)\n",
    "        out.write(END)\n",
    "        out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_singleton(df_pred, coref_group_conll_colName):\n",
    "    # remove singleton from df_pred\n",
    "    corefGroup_counter = Counter()\n",
    "    for conll_corefGroup_list_str in df_pred[~df_pred.loc[:, coref_group_conll_colName].isin([\"-1\", -1.0, np.nan])].loc[:, coref_group_conll_colName].to_list():\n",
    "        for conll_corefGroup_str in ast.literal_eval(conll_corefGroup_list_str):\n",
    "            result = re.search(r\"(\\d+)\\)\", conll_corefGroup_str)  # An coref mention always end with \"number)\"\n",
    "            if result:\n",
    "                corefGroup_counter.update([int(result.group(1))])\n",
    "\n",
    "    non_singletone_counter: list[tuple] = list(filter(lambda item: item[1] > 1, corefGroup_counter.items()))\n",
    "    coref_group_list_notSingleton = [int(k) for k, v in non_singletone_counter]\n",
    "    \n",
    "    # iter df rows, keep only the non_singleton coref id, and remove the others.\n",
    "    for idx, item in df_pred.iterrows():\n",
    "        conll_corefGroup_list_str = item.get(coref_group_conll_colName)\n",
    "        new_conll_corefGroup_str_list = []\n",
    "        # Remove singleton id\n",
    "        if conll_corefGroup_list_str in [\"-1\", -1.0, np.nan]:\n",
    "            continue\n",
    "        for conll_corefGroup_str in ast.literal_eval(conll_corefGroup_list_str):\n",
    "            res = re.match(r\"\\(?(\\d+)\\)?\",conll_corefGroup_str)\n",
    "            coref_group_id = int(res.groups()[0])\n",
    "            if coref_group_id in coref_group_list_notSingleton:\n",
    "                new_conll_corefGroup_str_list.append(conll_corefGroup_str)\n",
    "        df_pred.loc[idx,coref_group_conll_colName] = str(new_conll_corefGroup_str_list) if new_conll_corefGroup_str_list else -1\n",
    "    \n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../../resources/eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of gt docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dict_allDoc:dict[str,list] = {}\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    gt_all_dir = os.path.join(\"../../output/mimic_cxr/ground_truth\", section_name)\n",
    "    gt_dict_allDoc[section_name] = [i.rstrip(\".csv\") for i in FILE_CHECKER.filter(os.listdir(gt_all_dir))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of gt docs that has coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dict_hasCoref:dict[str,list] = {}\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    gt_all_dir = os.path.join(\"../../output/mimic_cxr/coref/individual_conll_ground_truth\", section_name)\n",
    "    gt_dict_hasCoref[section_name] = [i.rstrip(\".conll\") for i in FILE_CHECKER.filter(os.listdir(gt_all_dir))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general gt conll file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_conll_file_gt = os.path.join(output_dir, \"gt_100_noWhich.conll\")\n",
    "check_and_remove_file(output_conll_file_gt)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = gt_dict_allDoc[section_name]\n",
    "    for doc_id in doc_list:\n",
    "        input_conll_file = os.path.join(\"../../output/mimic_cxr/coref/individual_conll_ground_truth\", section_name, f\"{doc_id}.conll\")\n",
    "        if os.path.exists(input_conll_file):\n",
    "            copy_and_paste_conll(input_conll_file, output_conll_file_gt)\n",
    "        else:\n",
    "            input_csv_file = os.path.join(\"../../output/mimic_cxr/ground_truth\", section_name, f\"{doc_id}.csv\")\n",
    "            from_csv_to_conll(section_name, doc_id, output_conll_file_gt, input_csv_file, \"[gt]coref_group_conll\", \"[sp]sentence_group\",\"[sp]token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1-1: ensemble (majority voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1-1: Binary Eval (has coref / no coref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of predict docs that has coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_hasCoref: dict[str, list[str]] = {}\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    ensemble_dir = os.path.join(\"../../output/mimic_cxr/coref/individual_conll\", section_name)\n",
    "    pred_dict_hasCoref[section_name] = [i.rstrip(\".conll\") for i in FILE_CHECKER.filter(os.listdir(ensemble_dir))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = {}\n",
    "false_positive = {} # predict true, actual false\n",
    "false_negative = {} # predict false, actual true\n",
    "true_negative = {}\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    pred_hasCoref = set(pred_dict_hasCoref[section_name])\n",
    "    gt_hasCoref = set(gt_dict_hasCoref[section_name])\n",
    "    gt_all = set(gt_dict_allDoc[section_name])\n",
    "\n",
    "    true_positive[section_name] = pred_hasCoref.intersection(gt_hasCoref)\n",
    "    false_positive[section_name] = gt_all.intersection(pred_hasCoref) - gt_hasCoref\n",
    "    false_negative[section_name] = gt_hasCoref - pred_hasCoref\n",
    "    true_negative[section_name] = gt_all - pred_hasCoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "findings\n",
      "true_positive 21\n",
      "false_positive 1\n",
      "false_negative 10\n",
      "true_negative 28\n",
      "impression\n",
      "true_positive 21\n",
      "false_positive 1\n",
      "false_negative 12\n",
      "true_negative 28\n"
     ]
    }
   ],
   "source": [
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    print(section_name)\n",
    "    print(\"true_positive\",len(true_positive[section_name]))\n",
    "    print(\"false_positive\",len(false_positive[section_name]))\n",
    "    print(\"false_negative\",len(false_negative[section_name]))\n",
    "    print(\"true_negative\",len(true_negative[section_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'micro':\n",
    "Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "\n",
    "'macro':\n",
    "Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "'weighted':\n",
    "Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "\n",
    "'binary':\n",
    "Only report results for the class specified by pos_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42 22]\n",
      " [ 2 34]]\n",
      "\n",
      "precision, recall, f1, support(class_ele_num):\n",
      "micro: (0.76, 0.76, 0.76, None)\n",
      "macro: (0.7808441558441559, 0.8003472222222222, 0.7584541062801933, None)\n",
      "weigthed macro: (0.8294805194805196, 0.76, 0.763864734299517, None)\n",
      "binary has_coref [[ 0.95454545  0.65625     0.77777778 64.        ]]\n",
      "binary no_coref [[ 0.60714286  0.94444444  0.73913043 36.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "y_true = [\"has_coref\" if doc_id in gt_dict_hasCoref[section_name] else \"no_coref\" for section_name, doc_list in gt_dict_allDoc.items() for doc_id in doc_list]\n",
    "y_pred = [\"has_coref\" if doc_id in pred_dict_hasCoref[section_name] else \"no_coref\" for section_name, doc_list in gt_dict_allDoc.items() for doc_id in doc_list]\n",
    "confusion_arr = confusion_matrix(y_true, y_pred, labels=[\"has_coref\",\"no_coref\"])\n",
    "# TP FN\n",
    "# FP TN\n",
    "print(confusion_arr)\n",
    "print()\n",
    "\n",
    "micro_precision_recall_f1 = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "macro_precision_recall_f1 = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "weigthed_precision_recall_f1 = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "binary_precision_recall_f1 = precision_recall_fscore_support(y_true, y_pred, average=None, labels=[\"has_coref\",\"no_coref\"])\n",
    "precision,recall,f1,support = binary_precision_recall_f1\n",
    "\n",
    "print(\"precision, recall, f1, support(class_ele_num):\")\n",
    "print(\"micro:\", micro_precision_recall_f1)\n",
    "print(\"macro:\", macro_precision_recall_f1)\n",
    "print(\"weigthed macro:\", weigthed_precision_recall_f1)\n",
    "for i,j in zip([\"has_coref\",\"no_coref\"],np.matrix([precision,recall,f1,support]).getT()):\n",
    "    print(\"binary\",i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure() #this creates a new figure on which your plot will appear\n",
    "plt.tight_layout()\n",
    "\n",
    "ax = sns.heatmap(confusion_arr, xticklabels=[\"has_coref\", \"no_coref\"], yticklabels=[\"has_coref\", \"no_coref\"], annot=True, fmt='.2f')\n",
    "\n",
    "ax.set_xlabel('predict')\n",
    "ax.set_ylabel('ground-truth')\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1-2: CoNLL F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only TP (42 doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_conll_file_gt = os.path.join(output_dir, \"gt_42_noWhich.conll\")\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_42.conll\")\n",
    "check_and_remove_file(output_conll_file_gt)\n",
    "check_and_remove_file(output_conll_file_pred)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    for doc_id in true_positive[section_name]:\n",
    "        # gt\n",
    "        input_conll_file = os.path.join(\"../../output/mimic_cxr/coref/individual_conll_ground_truth\", section_name, f\"{doc_id}.conll\")\n",
    "        copy_and_paste_conll(input_conll_file, output_conll_file_gt)\n",
    "        # pred\n",
    "        input_conll_file = os.path.join(\"../../output/mimic_cxr/coref/individual_conll\", section_name, f\"{doc_id}.conll\")\n",
    "        copy_and_paste_conll(input_conll_file, output_conll_file_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TP + FP (42+2), which is the ensemble application scenario\n",
    "\n",
    "gt_44 (tp) + pred_44 (tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_conll_file_gt = os.path.join(output_dir, \"gt_44_noWhich.conll\")\n",
    "check_and_remove_file(output_conll_file_gt)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = list(true_positive[section_name]) # false_positive files are not existing here, thus ignore\n",
    "    for doc_id in doc_list:\n",
    "        input_conll_file = os.path.join(\"../../output/mimic_cxr/coref/individual_conll_ground_truth\", section_name, f\"{doc_id}.conll\")\n",
    "        copy_and_paste_conll(input_conll_file, output_conll_file_gt)\n",
    "\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_44.conll\")\n",
    "check_and_remove_file(output_conll_file_pred)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = list(true_positive[section_name]) + list(false_positive[section_name])\n",
    "    for doc_id in doc_list:\n",
    "        input_conll_file = os.path.join(\"../../output/mimic_cxr/coref/individual_conll\", section_name, f\"{doc_id}.conll\")\n",
    "        copy_and_paste_conll(input_conll_file, output_conll_file_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All (100), which is the actural conll scoring scenario.\n",
    "\n",
    "gt_100 + pred_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment 100x: Need to generate majority_voting gt files when only have fast_coref_onto_i2b2 outputs\n",
    "\n",
    "modify /config/coreference_resolution/coref_voting/mimic_cxr.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now = 2022-11-03 00:21:03.794004\n",
      "date and time = 2022-11-03 00:21:03\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.69it/s]\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from common_utils.coref_utils import shuffle_list\n",
    "import coref_voting\n",
    "from coref_voting import DocClass, MentionClass, compute_voting_result, get_output_df\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from nlp_ensemble.nlp_menbers import play_fastcoref\n",
    "\n",
    "mv_output_base_dir = os.path.join(\"../../output/mimic_cxr/coref_voting/majority_voting_eval100x\")\n",
    "\n",
    "config = None\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"create_ann\"):\n",
    "        config = compose(config_name=\"coreference_resolution\", overrides=[\"+coreference_resolution/coref_voting@_global_=mimic_cxr\"])\n",
    "\n",
    "def batch_processing3(config, spacy_file_path, section_name, file_name):\n",
    "    \"\"\" Voting on one document \"\"\"\n",
    "\n",
    "    START_EVENT.wait()\n",
    "\n",
    "    # Read spacy output as alignment base\n",
    "    df_spacy = pd.read_csv(spacy_file_path, index_col=0, na_filter=False)\n",
    "    # Some of the i2b2 raw files are utf-8 start with DOM, but we didn't remove the DOM character, thus we fix it here.\n",
    "    df_spacy.iloc[0] = df_spacy.iloc[0].apply(lambda x: x.replace(\"\\ufeff\", \"\").replace(\"\\xef\\xbb\\xbf\", \"\") if isinstance(x, str) else x)\n",
    "\n",
    "    docObj: DocClass = coref_voting.resolve_voting_info(config, df_spacy, section_name, file_name)\n",
    "    valid_mention_group: list[set[MentionClass]] = compute_voting_result(config, docObj)\n",
    "    df_out = get_output_df(config, df_spacy, valid_mention_group, docObj)\n",
    "\n",
    "    output_dir = os.path.join(mv_output_base_dir, section_name)\n",
    "    check_and_create_dirs(output_dir)\n",
    "    output_file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    df_out.to_csv(output_file_path)\n",
    "\n",
    "    return f\"{file_name} done.\"\n",
    "\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    # sample_num_str = \"{1: 544, 2: 544, 3: 295, 4: 83, 5: 25, 6: 6, 7: 2, 8: 1}\"\n",
    "    with ProcessPoolExecutor(max_workers=config.thread.workers) as executor:\n",
    "        all_task = []\n",
    "        doc_list = gt_dict_allDoc[section_name]\n",
    "        for doc_id in doc_list:\n",
    "            file_name = doc_id + \".csv\"\n",
    "            spacy_out_dir = os.path.join(config.input.source.baseline_model.dir, section_name)\n",
    "            spacy_file_path = os.path.join(spacy_out_dir, file_name)\n",
    "            all_task.append(executor.submit(batch_processing3, config, spacy_file_path, section_name, file_name))\n",
    "        \n",
    "         # Notify tasks to start\n",
    "        START_EVENT.set()\n",
    "\n",
    "        if all_task:\n",
    "            for future in tqdm(as_completed(all_task), total=len(all_task)):\n",
    "                msg = future.result()\n",
    "\n",
    "        executor.shutdown(wait=True, cancel_futures=False)\n",
    "        START_EVENT.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Have majority_voting gt files already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt: ../../resources/eval/gt_100_noWhich.conll\n",
      "pred: ../../resources/eval/pred_mv.conll\n",
      "Metric: muc\n",
      "mention_recall, mention_precision, mention_f1: 56.77, 75.17, 64.68\n",
      "coref_recall, coref_precision, coref_f1: 50.47, 67.94, 57.92\n",
      "Metric: bcub\n",
      "mention_recall, mention_precision, mention_f1: 56.77, 75.17, 64.68\n",
      "coref_recall, coref_precision, coref_f1: 52.12, 69.88, 59.71\n",
      "Metric: ceafe\n",
      "mention_recall, mention_precision, mention_f1: 56.77, 75.17, 64.68\n",
      "coref_recall, coref_precision, coref_f1: 54.74, 71.08, 61.84\n",
      "Overall F1: 59.82333333333333\n"
     ]
    }
   ],
   "source": [
    "output_conll_file_pred = os.path.join(output_dir, \"pred_mv.conll\")\n",
    "check_and_remove_file(output_conll_file_pred)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = gt_dict_allDoc[section_name]\n",
    "    for doc_id in doc_list:\n",
    "        input_csv_file = os.path.join(mv_output_base_dir, section_name, f\"{doc_id}.csv\")\n",
    "        from_csv_to_conll(section_name, doc_id, output_conll_file_pred, input_csv_file, \"[mv]coref_group_conll\", \"[sp]sentence_group\",\"[sp]token\")\n",
    "\n",
    "output_conll_file_gt = os.path.join(output_dir, \"gt_100_noWhich.conll\")\n",
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1-2: scoref, dcoref, fast_coref_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from nlp_ensemble.nlp_menbers import play_fastcoref\n",
    "\n",
    "config = None\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"statistic\"):\n",
    "        config = compose(config_name=\"nlp_ensemble\", overrides=[\"+statistic/coref_scoring@_global_=mimic_cxr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common way for testing scoref, dcoref, fast_coref_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistic.coref_socring import align_spacy_to_ground_truth, align_to_spacy, convert_non_spacy_token_csv_to_conll_format, convert_spacy_token_csv_to_conll_format, find_cloest_index\n",
    "\n",
    "csv_file_dir = \"../../output/mimic_cxr/nlp_ensemble/corenlp/dcoref\"\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_dcoref.conll\")\n",
    "check_and_remove_file(output_conll_file_pred)\n",
    "\n",
    "model_cfg = config.input.source.models.get(\"rb\") # ml -> scoref, rb -> dcoref, fj -> fast_coref_joint, fj2 -> fast_coref_onto_i2b2\n",
    "gt_cfg = config.input.ground_truth\n",
    "scorer_cfg = config.scorer\n",
    "spacy_cfg = config.input.spacy\n",
    "\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = gt_dict_allDoc[section_name]\n",
    "    for doc_id in tqdm(doc_list):\n",
    "        pred_file_path = os.path.join(csv_file_dir, section_name, f\"{doc_id}.csv\")\n",
    "        df_pred = pd.read_csv(pred_file_path, index_col=0, na_filter=False)\n",
    "        gt_file_path = os.path.join(\"../../output/mimic_cxr/ground_truth\", section_name, f\"{doc_id}.csv\")\n",
    "        df_gt = pd.read_csv(gt_file_path, index_col=0, na_filter=False)\n",
    "        spacy_file_path = os.path.join(\"../../output/mimic_cxr/nlp_ensemble/spacy\", section_name, f\"{doc_id}.csv\")\n",
    "        df_spacy = pd.read_csv(spacy_file_path, index_col=0, na_filter=False)\n",
    "\n",
    "        # Some of the i2b2 raw files are utf-8 start with DOM, but we didn't remove the DOM character, thus we fix it here.\n",
    "        df_gt.iloc[0] = df_gt.iloc[0].apply(lambda x: x.replace(\"\\ufeff\", \"\").replace(\"\\xef\\xbb\\xbf\", \"\") if isinstance(x, str) else x)\n",
    "        df_pred.iloc[0] = df_pred.iloc[0].apply(lambda x: x.replace(\"\\ufeff\", \"\").replace(\"\\xef\\xbb\\xbf\", \"\") if isinstance(x, str) else x)\n",
    "        df_spacy.iloc[0] = df_spacy.iloc[0].apply(lambda x: x.replace(\"\\ufeff\", \"\").replace(\"\\xef\\xbb\\xbf\", \"\") if isinstance(x, str) else x)\n",
    "\n",
    "        df_pred = remove_singleton(df_pred, model_cfg.target_column.coref_group_conll)\n",
    "\n",
    "        # Generate conll format predicted files\n",
    "        if model_cfg.align_to_spacy:\n",
    "\n",
    "            # Algin to spacy first, then align spacy to gt\n",
    "            model2spacy_tok_indices, coref_index_appearance_count_dict = align_to_spacy(config, model_cfg, df_spacy, df_pred)\n",
    "\n",
    "            gt_token_list = df_gt.loc[:, gt_cfg.target_column.token_for_alignment].tolist()\n",
    "            spacy_token_list = df_spacy.loc[:, spacy_cfg.target_column.token].tolist()\n",
    "            spacy2gt_tok_indices, _ = align_spacy_to_ground_truth(gt_token_list, spacy_token_list)\n",
    "            sentence_list_pred = convert_non_spacy_token_csv_to_conll_format(config, model_cfg, section_name, doc_id, coref_index_appearance_count_dict, model2spacy_tok_indices,\n",
    "                                                                             spacy2gt_tok_indices, df_pred, df_spacy)\n",
    "        else:\n",
    "            # Directly align to ground-truth\n",
    "            gt_token_list = df_gt.loc[:, gt_cfg.target_column.token_for_alignment].tolist()\n",
    "            spacy_token_list = df_pred.loc[:, model_cfg.target_column.token].tolist()\n",
    "            # Some token has conll label but does not exist in gt, that is what `empty_token_idx_with_conll_label_dict` is used for.\n",
    "            spacy2gt_tok_indices, empty_token_idx_with_conll_label_dict = align_spacy_to_ground_truth(\n",
    "                gt_token_list, spacy_token_list, df_spacy=df_spacy, spacy_cfg=spacy_cfg, df_pred=df_pred, model_cfg=model_cfg)\n",
    "            target_token_index_and_conll_label_dict = find_cloest_index(spacy2gt_tok_indices, empty_token_idx_with_conll_label_dict)\n",
    "            sentence_list_pred = convert_spacy_token_csv_to_conll_format(config, model_cfg, section_name, doc_id, spacy2gt_tok_indices, df_pred, target_token_index_and_conll_label_dict)\n",
    "\n",
    "\n",
    "        # Write conll\n",
    "        from_list_to_conll(output_conll_file_pred, doc_id, section_name, sentence_list_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_conll_file_gt = os.path.join(output_dir, \"gt_100_noWhich.conll\")\n",
    "# output_conll_file_pred = os.path.join(output_dir, \"pred_dcoref.conll\")\n",
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way for testing fast_coref_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt: ../../resources/eval/gt_100_noWhich.conll\n",
      "pred: ../../resources/eval/pred_fj2.conll\n",
      "Metric: muc\n",
      "mention_recall, mention_precision, mention_f1: 59.37, 74.5, 66.08\n",
      "coref_recall, coref_precision, coref_f1: 54.28, 67.05, 60.0\n",
      "Metric: bcub\n",
      "mention_recall, mention_precision, mention_f1: 59.37, 74.5, 66.08\n",
      "coref_recall, coref_precision, coref_f1: 55.42, 68.06, 61.09\n",
      "Metric: ceafe\n",
      "mention_recall, mention_precision, mention_f1: 59.37, 74.5, 66.08\n",
      "coref_recall, coref_precision, coref_f1: 55.8, 71.4, 62.64\n",
      "Overall F1: 61.24333333333334\n"
     ]
    }
   ],
   "source": [
    "gt_cfg = config.input.ground_truth\n",
    "scorer_cfg = config.scorer\n",
    "spacy_cfg = config.input.spacy\n",
    "\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_fj2.conll\")\n",
    "check_and_remove_file(output_conll_file_pred)\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = gt_dict_allDoc[section_name]\n",
    "    for doc_id in doc_list:\n",
    "        input_csv_file = os.path.join(\"../../output/mimic_cxr/nlp_ensemble/fast_coref_onto_i2b2\", section_name, f\"{doc_id}.csv\")\n",
    "        df_pred = pd.read_csv(input_csv_file, index_col=0, na_filter=False)\n",
    "        df_pred = remove_singleton(df_pred, \"[fj]coref_group_conll\")\n",
    "        from_csv_to_conll(section_name, doc_id, output_conll_file_pred, df_pred, \"[fj]coref_group_conll\", \"[fj]sentence_group\",\"[fj]token_from_spacy\")\n",
    "\n",
    "output_conll_file_gt = os.path.join(output_dir, \"gt_100_noWhich.conll\")\n",
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../../git_clone_repos/fast-coref/src\")\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from nlp_ensemble.nlp_menbers import play_fastcoref\n",
    "\n",
    "config = None\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"nlp_ensemble\"):\n",
    "        config = compose(config_name=\"nlp_ensemble\", overrides=[\"+nlp_ensemble@_global_=mimic_cxr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the variable: model_dir and output_conll_file_pred with correct path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model config %s metrics:\n",
      "- MUC\n",
      "- Bcub\n",
      "- CEAFE\n",
      "keep_singletons: false\n",
      "seed: 45\n",
      "train: true\n",
      "use_wandb: false\n",
      "override_encoder: true\n",
      "override_memory: false\n",
      "copy_from_pretrained_model: false\n",
      "continue_training: false\n",
      "paths:\n",
      "  resource_dir: ${infra.project_dir}/coref_resources\n",
      "  base_data_dir: ${paths.resource_dir}/data\n",
      "  conll_scorer: ${paths.resource_dir}/reference-coreference-scorers/scorer.pl\n",
      "  base_model_dir: ${infra.project_dir}/models\n",
      "  model_dir: /scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_mimic_206\n",
      "  best_model_dir: /scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_mimic_206/best\n",
      "  model_filename: model.pth\n",
      "  model_name: joint_train_onto_i2b2_mimic_206\n",
      "  model_name_prefix: coref_\n",
      "  model_path: /scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_mimic_206/model.pth\n",
      "  best_model_path: /scratch/c.c21051562/workspace/fast-coref/models/coref_joint_train_onto_i2b2_mimic_206/best/model.pth\n",
      "  doc_encoder_dirname: doc_encoder\n",
      "  pretrain_model_dir: ${paths.base_model_dir}/joint_best\n",
      "datasets:\n",
      "  ontonotes:\n",
      "    name: OntoNotes\n",
      "    cluster_threshold: 2\n",
      "    canonical_cluster_threshold: 2\n",
      "    targeted_eval: false\n",
      "    num_train_docs: 1000\n",
      "    num_dev_docs: 343\n",
      "    num_test_docs: 348\n",
      "    has_conll: true\n",
      "    singleton_file: null\n",
      "  i2b2:\n",
      "    name: i2b2\n",
      "    cluster_threshold: 2\n",
      "    canonical_cluster_threshold: 2\n",
      "    cross_val_split: 0\n",
      "    targeted_eval: false\n",
      "    num_train_docs: 296\n",
      "    num_dev_docs: 84\n",
      "    num_test_docs: 44\n",
      "    has_conll: true\n",
      "  mimic_cxr_1k:\n",
      "    name: mimic_cxr_1k\n",
      "    cluster_threshold: 2\n",
      "    canonical_cluster_threshold: 2\n",
      "    targeted_eval: false\n",
      "    num_train_docs: 997\n",
      "    num_dev_docs: 403\n",
      "    num_test_docs: 44\n",
      "    has_conll: true\n",
      "    singleton_file: null\n",
      "model:\n",
      "  doc_encoder:\n",
      "    transformer:\n",
      "      name: longformer\n",
      "      model_size: large\n",
      "      model_str: /home/yuxiangliao/PhD/workspace/git_clone_repos/fast-coref/models/longformer_coreference_joint\n",
      "      max_encoder_segment_len: 4096\n",
      "      max_segment_len: 4096\n",
      "    chunking: independent\n",
      "    finetune: false\n",
      "    add_speaker_tokens: true\n",
      "    speaker_start: '[SPEAKER_START]'\n",
      "    speaker_end: '[SPEAKER_END]'\n",
      "  memory:\n",
      "    mem_type:\n",
      "      name: unbounded\n",
      "      max_ents: null\n",
      "      eval_max_ents: null\n",
      "    emb_size: 20\n",
      "    mlp_size: 3000\n",
      "    mlp_depth: 1\n",
      "    sim_func: hadamard\n",
      "    entity_rep: wt_avg\n",
      "    num_feats: 2\n",
      "  mention_params:\n",
      "    max_span_width: 20\n",
      "    ment_emb: attn\n",
      "    use_gold_ments: false\n",
      "    use_topk: false\n",
      "    top_span_ratio: 0.4\n",
      "    emb_size: 20\n",
      "    mlp_size: 3000\n",
      "    mlp_depth: 1\n",
      "    ment_emb_to_size_factor:\n",
      "      attn: 3\n",
      "      endpoint: 2\n",
      "      max: 1\n",
      "  metadata_params:\n",
      "    use_genre_feature: false\n",
      "    default_genre: nw\n",
      "    genres:\n",
      "    - bc\n",
      "    - bn\n",
      "    - mz\n",
      "    - nw\n",
      "    - pt\n",
      "    - tc\n",
      "    - wb\n",
      "optimizer:\n",
      "  init_lr: 0.0003\n",
      "  fine_tune_lr: 1.0e-05\n",
      "  max_gradient_norm: 1.0\n",
      "  lr_decay: linear\n",
      "trainer:\n",
      "  dropout_rate: 0.3\n",
      "  label_smoothing_wt: 0.1\n",
      "  ment_loss: all\n",
      "  normalize_loss: false\n",
      "  max_evals: 20\n",
      "  to_save_model: true\n",
      "  log_frequency: 1000\n",
      "  patience: 10\n",
      "  eval_per_k_steps: 5000\n",
      "  num_training_steps: 100000\n",
      "  max_training_segments: 1\n",
      "infra:\n",
      "  is_local: false\n",
      "  job_time: 72000\n",
      "  job_id: 206\n",
      "  project_dir: /scratch/c.c21051562/workspace/fast-coref\n",
      "  work_dir: ${project_dir}/src/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Init model\n",
    "model_dir = \"../../../../git_clone_repos/fast-coref/models/coref_joint_train_onto_i2b2_mimic_206\"\n",
    "config.fastcoref_joint.model_dir = os.path.join(model_dir,\"best\") if os.path.exists(os.path.join(model_dir,\"best\")) else model_dir\n",
    "model, subword_tokenizer, max_segment_len = play_fastcoref.init_coref_model(config)\n",
    "\n",
    "output_conll_file_gt = os.path.join(output_dir, \"gt_100_noWhich.conll\")\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_model206.conll\")\n",
    "check_and_remove_file(output_conll_file_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  ../../../../git_clone_repos/fast-coref/models/coref_joint_train_onto_i2b2_mimic_206/best\n"
     ]
    }
   ],
   "source": [
    "print(\"Using: \",config.fastcoref_joint.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:21<00:00,  1.62s/it]\n",
      "100%|██████████| 50/50 [01:21<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from inference.tokenize_doc import tokenize_and_segment_doc\n",
    "from nlp_ensemble.nlp_menbers.play_fastcoref import inference, resolve_output\n",
    "from common_utils.nlp_utils import align_byIndex_individually_nestedgruop, align_coref_groups_in_conll_format\n",
    "\n",
    "spacy_nametyle = config.name_style.spacy.column_name\n",
    "fastcoref_joint_nametyle = config.name_style.fastcoref_joint.column_name\n",
    "\n",
    "# output_conll_file_pred = os.path.join(output_dir, \"pred_joint_best.conll\")\n",
    "# check_and_remove_file(output_conll_file_pred)\n",
    "\n",
    "for section_name in [\"findings\",\"impression\"]:\n",
    "    doc_list = gt_dict_allDoc[section_name]\n",
    "    for doc_id in tqdm(doc_list):\n",
    "        spacy_csv_file = os.path.join(\"../../output/mimic_cxr/nlp_ensemble/spacy\", section_name, f\"{doc_id}.csv\")\n",
    "        # Load preprocessed tokens from csv files.\n",
    "        df_base = pd.read_csv(spacy_csv_file, index_col=0)\n",
    "        tok_list = df_base.loc[:, spacy_nametyle.token].to_list()\n",
    "        sentGroup_list = df_base.loc[:, spacy_nametyle.sentence_group].to_list()\n",
    "        sent_tok_2d_list: list[list[str]] = []\n",
    "        for tok, sent_id in zip(tok_list, sentGroup_list):\n",
    "            tok = str(tok)  # In i2b2, some of the tokens might incorrectly be recognized as float type.\n",
    "            if len(sent_tok_2d_list) == sent_id:\n",
    "                sent_tok_2d_list.append([tok])\n",
    "            else:\n",
    "                sent_tok_2d_list[sent_id].append(tok)\n",
    "\n",
    "        # Using longformer tokenizer to generate subtokens and form the input data.\n",
    "        tokenized_doc = tokenize_and_segment_doc(sent_tok_2d_list, subword_tokenizer, max_segment_len=max_segment_len)\n",
    "\n",
    "        # Get model output\n",
    "        pred_mentions, pred_actions = inference(model, tokenized_doc)\n",
    "\n",
    "        # Resolve model output\n",
    "        coref_group_list = resolve_output(tokenized_doc, pred_mentions, pred_actions, ignore_singleton = True)\n",
    "\n",
    "        # To dataframe\n",
    "        df_fastcoref_joint = pd.DataFrame(\n",
    "            {\n",
    "                fastcoref_joint_nametyle[\"token_from_spacy\"]: [str(i) for i in tok_list],\n",
    "                fastcoref_joint_nametyle[\"sentence_group\"]: [int(i) for i in sentGroup_list],\n",
    "                fastcoref_joint_nametyle[\"coref_group\"]: [str(i) for i in align_byIndex_individually_nestedgruop(len(tok_list), coref_group_list)],\n",
    "                fastcoref_joint_nametyle[\"coref_group_conll\"]: [str(i) for i in align_coref_groups_in_conll_format(len(tok_list), coref_group_list)],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Overwrite csv\n",
    "        from_csv_to_conll(section_name, doc_id, output_conll_file_pred, df_fastcoref_joint, \"[fj]coref_group_conll\", \"[fj]sentence_group\",\"[fj]token_from_spacy\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval:\n",
    "\n",
    "If gt and pred conll files are existing, we can specify the path and run the following script directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt: ../../resources/eval/gt_100_noWhich.conll\n",
      "pred: ../../resources/eval/pred_model206.conll\n",
      "Metric: muc\n",
      "mention_recall, mention_precision, mention_f1: 60.41, 64.8, 62.53\n",
      "coref_recall, coref_precision, coref_f1: 53.33, 57.14, 55.17\n",
      "Metric: bcub\n",
      "mention_recall, mention_precision, mention_f1: 60.41, 64.8, 62.53\n",
      "coref_recall, coref_precision, coref_f1: 55.51, 59.29, 57.34\n",
      "Metric: ceafe\n",
      "mention_recall, mention_precision, mention_f1: 60.41, 64.8, 62.53\n",
      "coref_recall, coref_precision, coref_f1: 58.15, 62.46, 60.23\n",
      "Overall F1: 57.580000000000005\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "output_conll_file_gt = os.path.join(output_dir, \"gt_100_noWhich.conll\")\n",
    "# output_conll_file_pred = os.path.join(output_dir, \"pred_model305.conll\")\n",
    "compute_conll_score(output_conll_file_gt, output_conll_file_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mentions   Recall: 60.42  Precision: 66.29  F1: 63.22\n",
      "muc        Recall: 54.29  Precision: 59.38  F1: 56.72\n",
      "bcub       Recall: 56.03  Precision: 60.55  F1: 58.21\n",
      "ceafe      Recall: 57.70  Precision: 63.54  F1: 60.48\n",
      "lea        Recall: 52.60  Precision: 57.05  F1: 54.74\n",
      "CoNLL score: 58.47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "output_conll_file_gt = os.path.join(output_dir, \"gt_100_noWhich.conll\")\n",
    "output_conll_file_pred = os.path.join(output_dir, \"pred_model204.conll\")\n",
    "scorer_path = \"./wrong_conll_scorer_example/coval/scorer.py\"\n",
    "overall_f1 = []\n",
    "command = [\"python\", scorer_path, output_conll_file_gt, output_conll_file_pred]\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, check=True)\n",
    "out = result.stdout.decode('utf-8')\n",
    "err = result.stderr.decode('utf-8')\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('corenlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb6968a69f778f9e728e35b65cd79a0dbef5b20465434381676f63f710dc4a24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
