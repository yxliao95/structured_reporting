defaults:
  - /name_style/spacy_output
  - /name_style/majority_voting
  - /name_style/mimic_cxr_gt

# 0 to use random seed to shuffle the dataset; -1 to disable the shuffle; Or any int value as static seed.
shuffle_seed: 42

# If true, then the history output dir (include the temp_xx.base_dir) will be deleted and created again.
clear_history: False

thread:
  workers: 14

output:
  base_dir: ${mimic_cxr_output_dir}/coref
  run_statistic: ${output.base_dir}/coref_count.statistic
  log_file: ${output.base_dir}/run.log
  conll_dir_name: aggregrate_conll
  suffix: .conll

### For step 1-1
# Save individual conll files. Later when we need to sample and aggregrate conll files, we can copy from here.
# Generate individual conll files for model predicted data
temp_pred:
  base_dir: ${output.base_dir}/individual_conll
  detail_file_suffix: .dict

input_pred:
  base_dir: ${mimic_cxr_output_dir}/coref_voting/majority_voting
  suffix: .csv
  section:
    - findings
    - impression
    - provisional_findings_impression
    - findings_and_impression
  column_name:
    token: ${name_style.spacy.column_name.token}
    sentence_group: ${name_style.spacy.column_name.sentence_group}
    coref_group_conll: ${name_style.voting.column_name.coref_group_conll}

### For step 1-2
# Generate individual conll files for manual annotation data
temp_gt:
  force_run: False # If True, then the history output will be deleted
  base_dir: ${output.base_dir}/individual_conll_ground_truth/round4_100_1
  detail_file_suffix: .dict

input_gt:
  base_dir: ${mimic_cxr_output_dir}/manual_training_set/round4_100_1
  suffix: .csv
  section:
    - findings
    - impression
  column_name:
    token: ${name_style.spacy.column_name.token}
    sentence_group: ${name_style.spacy.column_name.sentence_group}
    coref_group_conll: ${name_style.mimic_cxr_gt.column_name.coref_group_conll}

### For step 3
# Will copy aggregrated conll files to /conll dir and generate .jsonlines files
longformer:
  source:
    - train: train_manual
    - dev: train_manual
    - test: test_gt

### For step 2
# Will generate aggregrate conll files to /aggregrate_conll dir 
data_split:
  activate:
    - train_manual
    - test_gt
  
  # The test set are manually annotated and saved in different dir. We will exclude the testset docs from train and dev, then construct the testset in an individual method
  train_dev_2k:
    dir_name: random_train_dev_2k
    samle_total: 2000
    sample_detail:
      # 3-8: 412, 4-8: 117
      - findings: "{1: 294, 2: 294, 3: 295, 4: 83, 5: 25, 6: 6, 7: 2, 8: 1}"
      # 3-7: 252, 4-7: 58
      - impression: "{1: 374, 2: 374, 3: 194, 4: 43, 5: 7, 6: 6, 7: 2}"
    output_name_prefix: train,dev # Should match to the length of ${data_split.if_split.proportion}
    proportion: 8,2 # 0.8 train, 0.2 dev. But not exactly the same as some of the doc might be used in the test set.
    test_docs_dir: ${mimic_cxr_output_dir}/manual_test_set/round_1x2 # Used to exclude the test docs from train and dev set.
  train_dev_1k:
    dir_name: random_train_dev_1k
    samle_total: 1250
    sample_detail:
      # 3-8: 412, 4-8: 117
      - findings: "{1: 170, 2: 170, 3: 170, 4: 83, 5: 25, 6: 6, 7: 2, 8: 1}"
      # 3-7: 252, 4-7: 58
      - impression: "{1: 189, 2: 189, 3: 189, 4: 43, 5: 7, 6: 6, 7: 2}"
    output_name_prefix: train,dev # Should match to the length of ${data_split.if_split.proportion}
    proportion: 8,2 # 0.8 train, 0.2 dev. But not exactly the same as some of the doc might be used in the test set.
    test_docs_dir: ${mimic_cxr_output_dir}/manual_test_set/round_1x2
  train_dev_4k:
    dir_name: random_train_dev_4k
    samle_total: 4000
    sample_detail:
      # 3-8: 412, 4-8: 117
      - findings: "{1: 794, 2: 794, 3: 295, 4: 83, 5: 25, 6: 6, 7: 2, 8: 1}"
      # 3-7: 252, 4-7: 58
      - impression: "{1: 874, 2: 874, 3: 194, 4: 43, 5: 7, 6: 6, 7: 2}"
    output_name_prefix: train,dev # Should match to the length of ${data_split.if_split.proportion}
    proportion: 8,2 # 0.8 train, 0.2 dev. But not exactly the same as some of the doc might be used in the test set.
    test_docs_dir: ${mimic_cxr_output_dir}/manual_test_set/round_1x2


  # The docs in `target_doc_dir` dir is the docs we want to get from the `source_dir`
  test_pred:
    dir_name: test_pred
    target_doc_dir: ${mimic_cxr_output_dir}/ground_truth_old
    source_dir: ${output.base_dir}/individual_conll
    source_file_suffix: .conll

  test_gt:
    dir_name: test_gt
    target_doc_dir: ${mimic_cxr_output_dir}/manual_test_set/round1x2
    source_dir: ${output.base_dir}/individual_conll_ground_truth/round1x2
    source_file_suffix: .conll

  train_manual:
    dir_name: train_manual
    target_doc_dir: ${mimic_cxr_output_dir}/manual_training_set/round4_200_1x2 
    source_dir: ${output.base_dir}/individual_conll_ground_truth/round4_200_1x2
    source_file_suffix: .conll
    output_name_prefix: train,dev # Should match to the length of ${data_split.if_split.proportion}
    proportion: 8,2 # 0.8 train, 0.2 dev. But not exactly the same as some of the doc might be used in the test set.

  # This is saved for using in notebook. 
  train_silver:
    dir_name: null