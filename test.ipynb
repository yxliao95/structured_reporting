{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':[1]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \":(1)\"\n",
    "\n",
    "if re.search(\"\\(?[^A-Za-z]+\\)?\",text):\n",
    "    text = text.replace(\"(\",\"[\").replace(\")\",\"]\")\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerTokenizerFast, AutoTokenizer\n",
    "\n",
    "# tokenizer = LongformerTokenizerFast.from_pretrained(\"allenai/longformer-base-4096\", add_prefix_space=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"shtoshni/longformer_coreference_joint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"The patient\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = [612, 613]\n",
    "tokenizer.decode(orig_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/liao/Desktop/DBMI_c2b2_2011_coref/longformer/all/all.4096.jsonlines\") as f:\n",
    "    tokenized_doc = json.loads(f.readlines()[1])\n",
    "    subtoken_map = tokenized_doc[\"subtoken_map\"]\n",
    "    orig_tokens = tokenized_doc[\"sentences\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subtoken_map[797:799])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orig_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subtoken_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subtoken_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/Users/liao/Desktop/DBMI_c2b2_2011_coref/longformer/all/all.4096.jsonlines\") as f:\n",
    "    tokenized_doc = json.loads(f.readlines()[1])\n",
    "    subtoken_map = tokenized_doc[\"subtoken_map\"]\n",
    "    subtoken_id = tokenized_doc[\"sentences\"][0]\n",
    "    clusters = []\n",
    "    for idx_cluster in tokenized_doc[\"clusters\"]:\n",
    "        cur_cluster = []\n",
    "        for (ment_start, ment_end) in idx_cluster:\n",
    "            coref_id = subtoken_id[ment_start : ment_end + 1]\n",
    "            coref_str = tokenizer.decode(coref_id)\n",
    "            cur_cluster.append(((ment_start, ment_end), coref_str,))\n",
    "\n",
    "        clusters.append(cur_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(clusters))\n",
    "for cluster in clusters:\n",
    "    print(cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbe186fad143582492f874971b555a6a67ca040c11267037e80d88fc47d0fa6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
