{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yuxiangliao/PhD'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "from loguru import logger\n",
    "\n",
    "LOG_ROOT = os.path.abspath(\"./\")\n",
    "LOG_FILE = LOG_ROOT + \"/logs/sr-3.log\"\n",
    "\n",
    "# Remove all handlers and reset stderr\n",
    "logger.remove(handler_id=None)\n",
    "logger.add(\n",
    "    LOG_FILE,\n",
    "    level=\"TRACE\",\n",
    "    mode=\"w\",\n",
    "    backtrace=False,\n",
    "    diagnose=True,\n",
    "    colorize=False,\n",
    "    format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}\",\n",
    ")\n",
    "logger.info(\"\\r\\n\" + \">\" * 29 + \"\\r\\n\" + \">>> New execution started >>>\" + \"\\r\\n\" + \">\" * 29)\n",
    "# To filter log level: TRACE=5, DEBUG=10, INFO=20, SUCCESS=25, WARNING=30, ERROR=40, CRITICAL=50\n",
    "logger.add(sys.stdout, level=\"INFO\", filter=lambda record: record[\"level\"].no < 40, colorize=True)\n",
    "logger.add(sys.stderr, level=\"ERROR\", backtrace=False, diagnose=True, colorize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Metamap\n",
    "\n",
    "Follow the following instructions:\n",
    "- Install Metamap2020: https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/documentation/Installation.html \n",
    "- Install additional datasets (2022 Specialist Lexicon, 2022AA UMLS NLM Datasets): https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/additional-tools/DataSetDownload.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the servers started\n",
    "- taggerServer\n",
    "- DisambiguatorServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yuxiang+   31170    1377  0 Jul08 ?        00:07:55 java -Dtaggerserver.port=1795 -DlexFile=/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/MedPost-SKR/data/lexDB.serial -DngramOne=/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/MedPost-SKR/data/ngramOne.serial -cp /home/yuxiangliao/PhD/UMLS/Metamap/public_mm/MedPost-SKR/Tagger_server/lib/taggerServer.jar:/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/MedPost-SKR/Tagger_server/lib/mps.jar taggerServer\n",
      "yuxiang+   31218    1377  0 Jul08 ?        00:08:30 java -Xmx2g -Dserver.config.file=/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/WSD_Server/config/disambServer.cfg -classpath /home/yuxiangliao/PhD/UMLS/Metamap/public_mm/WSD_Server/lib/metamapwsd.jar:/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/WSD_Server/lib/utils.jar:/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/WSD_Server/lib/lucene-core-3.0.1.jar:/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/WSD_Server/lib/monq-1.1.1.jar:/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/WSD_Server/lib/wsd.jar:/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/WSD_Server/lib/kss-api.jar:/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/WSD_Server/lib/thirdparty.jar:/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/WSD_Server/lib/db.jar:/home/yuxiangliao/PhD/UMLS/Metamap/public_mm/WSD_Server/lib/log4j-1.2.8.jar wsd.server.DisambiguatorServer\n",
      "yuxiang+  170562  158343  0 19:48 ?        00:00:00 /bin/sh -c ps -ef | grep java\n",
      "yuxiang+  170564  170562  0 19:48 ?        00:00:00 grep java\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cmd = 'ps -ef | grep java'\n",
    "out = os.popen(cmd)\n",
    "print(out.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check metamap human readable output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess, shlex\n",
    "# text =  \"There is no focal consolidation, pleural effusion or pneumothorax.  Cardiomediastinal silhouette and hilar contours are otherwise unremarkable.\"\n",
    "# input_command = f\"echo -e {text}\"\n",
    "# input_process = subprocess.Popen(shlex.split(input_command), stdout=subprocess.PIPE)\n",
    "# meta_command = \"metamap -V NLM -Z 2022AA -A --silent -I\"\n",
    "# metamap_process = subprocess.Popen(shlex.split(meta_command), stdout=subprocess.PIPE, stdin=input_process.stdout)\n",
    "# output, error = metamap_process.communicate()\n",
    "# print(output.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pid        sid  \\\n",
      "0       p10000032  s50414267   \n",
      "1       p10000032  s53189527   \n",
      "2       p10000032  s53911762   \n",
      "3       p10000032  s56699142   \n",
      "4       p10000764  s57375967   \n",
      "...           ...        ...   \n",
      "227830  p19999442  s58708861   \n",
      "227831  p19999733  s57132437   \n",
      "227832  p19999987  s55368167   \n",
      "227833  p19999987  s58621812   \n",
      "227834  p19999987  s58971208   \n",
      "\n",
      "                                                 findings  \\\n",
      "0       There is no focal consolidation, pleural effus...   \n",
      "1       The cardiac, mediastinal and hilar contours ar...   \n",
      "2       Single frontal view of the chest provided. \\n ...   \n",
      "3       The lungs are clear of focal consolidation, pl...   \n",
      "4       PA and lateral views of the chest provided.   ...   \n",
      "...                                                   ...   \n",
      "227830  ET tube ends 4.7 cm above the carina.  NG tube...   \n",
      "227831  The lungs are clear, and the cardiomediastinal...   \n",
      "227832  There has been interval extubation and improve...   \n",
      "227833  Portable supine AP view of the chest provided ...   \n",
      "227834  The ET tube terminates approximately 2.9 cm fr...   \n",
      "\n",
      "                                               impression  \\\n",
      "0                       No acute cardiopulmonary process.   \n",
      "1                   No acute cardiopulmonary abnormality.   \n",
      "2                         No acute intrathoracic process.   \n",
      "3                       No acute cardiopulmonary process.   \n",
      "4       Focal consolidation at the left lung base, pos...   \n",
      "...                                                   ...   \n",
      "227830  1.  Lines and tubes are in adequate position. ...   \n",
      "227831                   No acute cardiothoracic process.   \n",
      "227832                                                      \n",
      "227833  Appropriately positioned ET and NG tubes.  Bib...   \n",
      "227834  Slight interval worsening of right lower lung ...   \n",
      "\n",
      "       provisional_findings_impression findings_and_impression  \n",
      "0                                                               \n",
      "1                                                               \n",
      "2                                                               \n",
      "3                                                               \n",
      "4                                                               \n",
      "...                                ...                     ...  \n",
      "227830                                                          \n",
      "227831                                                          \n",
      "227832                                                          \n",
      "227833                                                          \n",
      "227834                                                          \n",
      "\n",
      "[227835 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "REPORT_PATH = \"/home/yuxiangliao/PhD/data/mimic_cxr_reports_core.json\"\n",
    "df = pd.read_json(REPORT_PATH,orient=\"records\",lines=True)\n",
    "print(df)\n",
    "\n",
    "id_list = df.loc[:,'sid'].to_list()\n",
    "findings_list = df.loc[:,'findings'].to_list()\n",
    "impression_list = df.loc[:,'impression'].to_list()\n",
    "pfi_list = df.loc[:,'provisional_findings_impression'].to_list()\n",
    "fai_list = df.loc[:,'findings_and_impression'].to_list()\n",
    "\n",
    "DATA_SIZE = len(id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run multiprocessing in jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct metama command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, shlex\n",
    "# Documentation: https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/MM_2016_Usage.pdf\n",
    "def get_metamap_command():\n",
    "    command = format_command_arg(\"metamap\")\n",
    "    command += format_command_arg(\"-V NLM\")                # Data Version: -V (--mm data version) [Base, USAbase, NLM]\n",
    "    command += format_command_arg(\"-Z 2022AA\")             # Knowledge Source: -Z (--mm data year)\n",
    "    command += format_command_arg(\"-A\")                    # Data Model: [-A (--strict model), -C (--relaxed model)]\n",
    "    command += format_command_arg(\"--silent\")              # Hide Header Output: --silent\n",
    "    command += format_command_arg(\"--JSONn\")               # Output format: [-q (--machine output), --XMLf, --XMLn, --XMLf1, --XMLn1, --JSONf, --JSONn, -N (--fielded mmi output), -F (--formal tagger output)]\n",
    "    # command += \" --conj\"                                   # Turn on Conjunction Processing\n",
    "    # command += \" -y\"                                       # Word-Sense Disambiguation: -y (--word sense disambiguation)\n",
    "    # UDA_path = \"/home/yuxiangliao/PhD/UMLS/custom-resources/custom-word-replacement\"\n",
    "    # command += format_command_arg(f\"--UDA {UDA_path}\")     # User-Defined Acronyms/Abbreviations (word replacement): --UDA <file>\n",
    "    # semantic_types = \"virs,cgab,acab,ffas,bpoc,medd,tmco,qlco,qnco,bsoj,blor,fndg,sosy,topp,ortf,patf,dsyn,inpo\"\n",
    "    # commend += f\"-J {semantic_types}\"                      # Retain only Concepts with Specified Semantic Types: -J (--restrict to sts) <list>\n",
    "    # command += format_command_arg(\"-I\")                    # For human readable output\n",
    "    return command\n",
    "\n",
    "def format_command_arg(arg):\n",
    "    return \" \" + arg\n",
    "\n",
    "def run_metamap(startIndex,batch_size):\n",
    "    endIndex = startIndex + batch_size if startIndex + batch_size < DATA_SIZE else DATA_SIZE\n",
    "    input_list = [(record if record else \"None\") for record in findings_list[startIndex:endIndex]]\n",
    "    input = repr(\"\\n\\n\".join(input_list))\n",
    "    input_command = f\"echo -e {input}\"\n",
    "    input_process = subprocess.Popen(shlex.split(input_command), stdout=subprocess.PIPE)\n",
    "    \n",
    "    meta_command = get_metamap_command()\n",
    "    metamap_process = subprocess.Popen(shlex.split(meta_command), stdout=subprocess.PIPE, stdin=input_process.stdout)\n",
    "   \n",
    "    output_bytes, error_bytes = metamap_process.communicate()\n",
    "    if error_bytes:\n",
    "        logger.error(error_bytes.decode())\n",
    "    return output_bytes.decode(), [startIndex,endIndex], input_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Object for JSON output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Concept(object):\n",
    "    def __init__(self, sourceTokens:list, startPosList:list, lengthList:list, umlsCUI:str, preferedName:str, hitTerm:str, categories:list, isHead:int, isNegated:int):\n",
    "        self.sourceTokens = sourceTokens\n",
    "        self.startPosList = startPosList\n",
    "        self.lengthList = lengthList\n",
    "        self.umlsCUI = umlsCUI\n",
    "        self.preferedName = preferedName\n",
    "        self.hitTerm = hitTerm\n",
    "        self.categories = categories\n",
    "        self.isHead =  isHead\n",
    "        self.isNegated =  isNegated\n",
    "        \n",
    "class ConceptGroup(object):\n",
    "    def __init__(self):\n",
    "        self.concepts = []\n",
    "    def addConcept(self, concept:Concept):\n",
    "        self.concepts.append(concept)\n",
    "        \n",
    "class SyntaxChunk(object):\n",
    "    def __init__(self, text:str, lexicalMatch:str, syntaxType:str, partOfSpeech:str, tokens:list):\n",
    "        self.text = text # The original form of the text (case sensitive)\n",
    "        self.lexicalMatch = lexicalMatch\n",
    "        self.syntaxType = syntaxType\n",
    "        self.partOfSpeech = partOfSpeech\n",
    "        self.tokens = tokens\n",
    "                \n",
    "class Phrase(object):\n",
    "    def __init__(self, text:str, startPos:int, length:int):\n",
    "        self.text = text\n",
    "        self.startPos = startPos\n",
    "        self.length = length\n",
    "        self.syntaxChunks = []\n",
    "        self.mappings = []\n",
    "    def addSyntaxChunk(self, syntaxChunk:SyntaxChunk):\n",
    "        self.syntaxChunks.append(syntaxChunk)\n",
    "    def addConceptGroup(self, conceptGroup:ConceptGroup):\n",
    "        self.mappings.append(conceptGroup)\n",
    "        \n",
    "        \n",
    "class Sentence(object):\n",
    "    def __init__(self, text:str, startPos:int, length:int):\n",
    "        self.text = text\n",
    "        self.startPos = startPos\n",
    "        self.length = length\n",
    "        self.phrases = []\n",
    "    def addPhrase(self, phrase:Phrase):\n",
    "        self.phrases.append(phrase)\n",
    "\n",
    "class Negation(object):\n",
    "    def __init__(self, text:str, triStartPosList:list, triLengthList:list, conceptsCUIs:list, tarStartPosList:list, tarLengthList:list):\n",
    "        self.trgger = {\n",
    "            'text': text,\n",
    "            'startPosList': triStartPosList,\n",
    "            'lengthList': triLengthList,\n",
    "        }\n",
    "        self.tarrget = {\n",
    "            'conceptsCUIs': conceptsCUIs,\n",
    "            'startPosList': tarStartPosList,\n",
    "            'lengthList': tarLengthList,\n",
    "        }\n",
    "\n",
    "class Section(object):\n",
    "    def __init__(self, name:str):\n",
    "        self.name = name\n",
    "        self.text = \"\" # context\n",
    "        self.sentences = []\n",
    "        self.negations = []\n",
    "    def addSentence(self, sentence:Sentence):\n",
    "        self.sentences.append(sentence)\n",
    "        self.text += sentence.text\n",
    "    def addNegation(self, negation:Negation):\n",
    "        self.negations.append(negation)\n",
    "        \n",
    "class Record(object):\n",
    "    def __init__(self, sid:str):\n",
    "        self.sid = sid\n",
    "        self.sections = []\n",
    "    def addSection(self, section:Section):\n",
    "        self.sections.append(section)\n",
    "    def getFindingSection(self) -> Section:\n",
    "        assert self.sections[0].name == \"findings\"\n",
    "        return self.sections[0]\n",
    "        \n",
    "class Records(object):\n",
    "    def __init__(self):\n",
    "        self.records = []\n",
    "    def addRecord(self, record:Record):\n",
    "        self.records.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods to resolve specific JSON subtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolveSyntaxUnit(syntaxUnit):\n",
    "    text = syntaxUnit['InputMatch']\n",
    "    syntaxType = syntaxUnit['SyntaxType']\n",
    "    tokens = syntaxUnit['Tokens']\n",
    "    # Add punc to token list\n",
    "    if not tokens:\n",
    "        logger.trace(f\"Empty token detected: SyntaxType:{syntaxType}, InputMatch:{text}\")\n",
    "        tokens = [text]\n",
    "    try:\n",
    "        lexicalMatch = syntaxUnit['LexMatch']\n",
    "        partOfSpeech = syntaxUnit['LexCat']\n",
    "    except KeyError:\n",
    "        lexicalMatch = \"\"\n",
    "        partOfSpeech = \"\"\n",
    "    if text.lower() != lexicalMatch and text.isalnum():\n",
    "        logger.trace(f\"text:[{text}], lexicalMatch:[{lexicalMatch}]\")\n",
    "    return SyntaxChunk(text, lexicalMatch, syntaxType, partOfSpeech, tokens)\n",
    "\n",
    "def resolveConcept(mappingCandidate):\n",
    "    sourceTokens = mappingCandidate['MatchedWords']\n",
    "    startPosList = [int(i['StartPos']) for i in mappingCandidate['ConceptPIs']]\n",
    "    lengthList = [int(i['Length']) for i in mappingCandidate['ConceptPIs']]\n",
    "    umlsCUI = mappingCandidate['CandidateCUI']\n",
    "    preferedName = mappingCandidate['CandidatePreferred']\n",
    "    hitTerm = mappingCandidate['CandidateMatched']\n",
    "    categories = mappingCandidate['SemTypes']\n",
    "    isHead = 1 if mappingCandidate['IsHead'] == \"yes\" else 0\n",
    "    isNegated = 1 if mappingCandidate['Negated'] == \"1\" else 0\n",
    "    return Concept(sourceTokens, startPosList, lengthList, umlsCUI, preferedName, hitTerm, categories, isHead, isNegated)\n",
    "\n",
    "def resolveNegation(negation):\n",
    "    trigger = negation['NegTrigger']\n",
    "    triggerStartPosList = [int(i['StartPos']) for i in negation['NegTriggerPIs']]\n",
    "    triggerLengthList = [int(i['Length']) for i in negation['NegTriggerPIs']]\n",
    "    conceptCUIs = [i['NegConcCUI'] for i in negation['NegConcepts']]\n",
    "    targetStartPosList = [int(i['StartPos']) for i in negation['NegConcPIs']]\n",
    "    targetLengthList = [int(i['Length']) for i in negation['NegConcPIs']]\n",
    "    return Negation(trigger, triggerStartPosList, triggerLengthList, conceptCUIs, targetStartPosList, targetLengthList)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to resolve JSON format output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseMetamapJSON(json_obj,id_subList) -> Records:\n",
    "    records = Records()\n",
    "    for _idx, _document in enumerate(json_obj['AllDocuments']):\n",
    "        # print(_document.keys())\n",
    "        # print(record['Document']['Negations'])\n",
    "        record = Record(id_subList[_idx])\n",
    "        section = Section(\"findings\")\n",
    "        for _utterance in _document['Document']['Utterances']:\n",
    "            # print(_utterance.keys())\n",
    "            sentence = Sentence(text=_utterance['UttText'], startPos=int(_utterance['UttStartPos']), length=int(_utterance['UttLength']))\n",
    "            for _phrase in _utterance['Phrases']:\n",
    "                # print(_phrase.keys())\n",
    "                phrase = Phrase(text=_phrase['PhraseText'], startPos=int(_phrase['PhraseStartPos']), length=int(_phrase['PhraseLength']))\n",
    "                for _syntaxUnit in _phrase['SyntaxUnits']:\n",
    "                    # print(_syntaxUnit.keys())\n",
    "                    syntaxChunk = resolveSyntaxUnit(_syntaxUnit)\n",
    "                    phrase.addSyntaxChunk(syntaxChunk)\n",
    "                for _mapping in _phrase['Mappings']:\n",
    "                    # print(_mapping.keys())\n",
    "                    conceptGroup = ConceptGroup()\n",
    "                    for _mappingCandidate in _mapping['MappingCandidates']:\n",
    "                        # print(_mappingCandidate.keys())\n",
    "                        concept = resolveConcept(_mappingCandidate)\n",
    "                        conceptGroup.addConcept(concept)\n",
    "                    phrase.addConceptGroup(conceptGroup)\n",
    "                sentence.addPhrase(phrase)\n",
    "            section.addSentence(sentence)\n",
    "        for _negation in _document['Document']['Negations']:\n",
    "            negation = resolveNegation(_negation)\n",
    "            section.addNegation(negation)\n",
    "        record.addSection(section)\n",
    "        records.addRecord(record)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods to align the metamap output to the spacy output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "from operator import itemgetter\n",
    "\n",
    "def align(baseList:Doc, inputTokenGroups):\n",
    "    alignment= [-1] * len(baseList)\n",
    "    for id, tokenGroup in enumerate(inputTokenGroups):\n",
    "        alignment[tokenGroup.start:tokenGroup.end] = [id] * (tokenGroup.end-tokenGroup.start)\n",
    "    return alignment\n",
    "\n",
    "def align_byIndex(baseList:Doc, inputIndexGroups):\n",
    "    alignment= [-1] * len(baseList)\n",
    "    for id, indexGroup in enumerate(inputIndexGroups):\n",
    "        alignment[indexGroup[0]:indexGroup[-1]+1] = [id] * len(indexGroup)\n",
    "    return alignment\n",
    "\n",
    "def align_byIndex_individually_withData_noOverlap(baseList:Doc, inputIndexGroups_withData):\n",
    "    alignment= [-1] * len(baseList)\n",
    "    for id, indexGroup_withData in enumerate(inputIndexGroups_withData):\n",
    "        indexGroup = indexGroup_withData['indices']\n",
    "        extra_str = indexGroup_withData['extra_str']\n",
    "        for index in indexGroup:\n",
    "            alignment[index] = f\"{id}|{extra_str}\"\n",
    "    return alignment\n",
    "\n",
    "def align_byIndex_individually_withData(baseList:Doc, inputIndexGroups_withData):\n",
    "    alignment= [-1] * len(baseList)\n",
    "    for id, indexGroup_withData in enumerate(inputIndexGroups_withData):\n",
    "        indexGroup = indexGroup_withData['indices']\n",
    "        extra_str = indexGroup_withData['extra_str']\n",
    "        for index in indexGroup:\n",
    "            if alignment[index] == -1:\n",
    "                alignment[index] = [extra_str]\n",
    "            else:\n",
    "                alignment[index].append(extra_str) \n",
    "    return alignment\n",
    "\n",
    "def getTokenOffset(baseText:str, inputTokens):\n",
    "    startPos = 0\n",
    "    offset= []\n",
    "    for token in inputTokens:\n",
    "        offsetPos = baseText.find(token.text, startPos, len(baseText))\n",
    "        offset.append(offsetPos)\n",
    "        startPos = offsetPos + len(token.text)\n",
    "    return offset\n",
    "\n",
    "def resolveTokenIndices_byPosition(tokenOffset, startPos, length) -> list:\n",
    "    indicesList = []\n",
    "    doInsert = False\n",
    "    posPointer = startPos\n",
    "    for i, currPos in enumerate(tokenOffset):\n",
    "        nextPos = tokenOffset[i+1] if i + 1 < len(tokenOffset) else tokenOffset[i] + 99\n",
    "        if not doInsert and posPointer >= currPos and posPointer < nextPos:\n",
    "            doInsert = True\n",
    "            posPointer = startPos + length - 1\n",
    "        elif doInsert and posPointer < currPos: \n",
    "            break # break the loop in advance, othewise will stop when finish the loop.\n",
    "        if doInsert:\n",
    "            indicesList.append(i)\n",
    "    return indicesList\n",
    "\n",
    "def resolveTokenIndices_byPosition_multiToken(tokenOffset, startPosList, lengthList) -> list:\n",
    "    idxList_3d = [resolveTokenIndices_byPosition(tokenOffset, startPos, length) for startPos, length in zip(startPosList, lengthList)]\n",
    "    idxList_flatten = [idx for idxList in idxList_3d for idx in idxList]\n",
    "    return idxList_flatten\n",
    "\n",
    "def trimIndices(_indices, keepNum):\n",
    "    interval = []\n",
    "    for id, current in enumerate(_indices):\n",
    "        if id == len(_indices)-1:\n",
    "            break\n",
    "        nextid = id+1\n",
    "        next = _indices[nextid]\n",
    "        interval.append(next-current)\n",
    "    interval_withIdx = list(enumerate(interval))\n",
    "    trimed_list = sorted(interval_withIdx,key=itemgetter(1))[0:keepNum-1]\n",
    "    idx_remained = set()\n",
    "    for i in trimed_list:\n",
    "        idx_remained.add(i[0])\n",
    "        idx_remained.add(i[0]+1)\n",
    "    return [_indices[i] for i in idx_remained]\n",
    "\n",
    "def replPunc(matchObj):\n",
    "    if matchObj.string == matchObj.group(0):\n",
    "        return matchObj.string\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "def findSubString(sourceText,subStr,subStr_tokens,begin):\n",
    "    sourceText = sourceText.lower()\n",
    "    startPos = sourceText.find(subStr.lower(),begin)\n",
    "    if startPos != -1:\n",
    "        return startPos, len(subStr)\n",
    "    else: \n",
    "        # Sometimes metamap will rewrite the text, making the subStr differ to the source text.\n",
    "        # In this case, we use token.\n",
    "        if subStr_tokens:\n",
    "            subStr_tokens = [i.lower() for i in subStr_tokens]\n",
    "            startPos = sourceText.find(subStr_tokens[0],begin)\n",
    "            assert startPos!=-1\n",
    "            nextStartPos = startPos + len(subStr_tokens[0])\n",
    "            for token in subStr_tokens[1:]:\n",
    "                nextStartPos = sourceText.find(token,nextStartPos)\n",
    "                nextStartPos += len(token)\n",
    "            assert nextStartPos-startPos>0\n",
    "            return startPos, nextStartPos-startPos\n",
    "        else:\n",
    "            return begin, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonpickle\n",
    "\n",
    "def classToJSON(obj) -> str:\n",
    "\n",
    "    return jsonpickle.encode(obj,unpicklable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format metamap outputs so that it can be aligned to spacy tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatMetamapRecord(metamapRecord):\n",
    "    reportText = metamapRecord.getFindingSection().text\n",
    "    phrases = [phrase for sentence in metamapRecord.getFindingSection().sentences for phrase in sentence.phrases]\n",
    "    tokenOffset = spacyOutput.loc[:,SPACY_COLUMN_NAME['token_offset']].tolist()\n",
    "    phraseIdxGroups = []\n",
    "    syntaxChunkIdxGroups_withData = []\n",
    "    conceptIdxGroup_withData = []\n",
    "    negTriggerGroups_withData = []\n",
    "    negTargetGroups_withData = []\n",
    "    conceptGroupId = 0\n",
    "    negationGroupId = 0\n",
    "    offsetBegin = 0\n",
    "    for phrase in phrases:\n",
    "        phraseIdxList = resolveTokenIndices_byPosition(tokenOffset, phrase.startPos, phrase.length)\n",
    "        phraseIdxGroups.append(phraseIdxList)\n",
    "        for syntaxChunk in phrase.syntaxChunks:\n",
    "            startPos, length = findSubString(reportText,syntaxChunk.text,syntaxChunk.tokens,offsetBegin)\n",
    "            offsetBegin = startPos + length\n",
    "            syntaxChunkIdxGroups_withData.append({\n",
    "                \"indices\": resolveTokenIndices_byPosition(tokenOffset, startPos, length),\n",
    "                \"extra_str\": f\"{syntaxChunk.syntaxType}|{syntaxChunk.partOfSpeech}|{syntaxChunk.tokens}\"\n",
    "            })\n",
    "        for conceptGroup in phrase.mappings:\n",
    "            for concept in conceptGroup.concepts:\n",
    "                conceptIdxList_flatten = resolveTokenIndices_byPosition_multiToken(tokenOffset, concept.startPosList, concept.lengthList)\n",
    "                conceptIdxGroup_withData.append({\n",
    "                    \"indices\":conceptIdxList_flatten,\n",
    "                    \"extra_str\":f\"{conceptGroupId}|{concept.umlsCUI}|{concept.preferedName}({concept.hitTerm})|{','.join(concept.categories)}|{concept.isHead}|{concept.isNegated}\",\n",
    "                })\n",
    "            conceptGroupId += 1\n",
    "    for negation in metamapRecord.getFindingSection().negations:\n",
    "        negTriggerIdxList_flatten = resolveTokenIndices_byPosition_multiToken(tokenOffset, negation.trgger['startPosList'], negation.trgger['lengthList'])\n",
    "        negTargetIdxList_flatten = resolveTokenIndices_byPosition_multiToken(tokenOffset, negation.tarrget['startPosList'], negation.tarrget['lengthList'])\n",
    "        negTriggerGroups_withData.append({\n",
    "            \"indices\": negTriggerIdxList_flatten,\n",
    "            \"extra_str\":f\"{negationGroupId}|{','.join([str(i) for i in negTargetIdxList_flatten])}|{','.join(negation.tarrget['conceptsCUIs'])}\"\n",
    "        })\n",
    "        negTargetGroups_withData.append({\n",
    "            \"indices\": negTargetIdxList_flatten,\n",
    "            \"extra_str\":f\"{negationGroupId}|{','.join([str(i) for i in negTriggerIdxList_flatten])}|{','.join(negation.tarrget['conceptsCUIs'])}\"\n",
    "        })\n",
    "        negationGroupId += 1\n",
    "    return phraseIdxGroups, syntaxChunkIdxGroups_withData, conceptIdxGroup_withData, negTriggerGroups_withData, negTargetGroups_withData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACY_PREFIXX = \"[sp]\"\n",
    "SPACY_COLUMN_NAME = {\n",
    "    'token': SPACY_PREFIXX+'token',\n",
    "    'token_offset':SPACY_PREFIXX+'token_offset',\n",
    "    'sentence_group':SPACY_PREFIXX+'sentence_group',\n",
    "    'noun_chunk':SPACY_PREFIXX+'noun_chunk',\n",
    "    'lemma':SPACY_PREFIXX+'lemma',\n",
    "    'pos_core':SPACY_PREFIXX+'pos_core',\n",
    "    'pos_feature':SPACY_PREFIXX+'pos_feature',\n",
    "    'dependency':SPACY_PREFIXX+'dependency',\n",
    "    'dependency_head':SPACY_PREFIXX+'dependency_head',\n",
    "    'dependency_children':SPACY_PREFIXX+'dependency_children',\n",
    "    'morphology':SPACY_PREFIXX+'morphology',\n",
    "    'is_alpha':SPACY_PREFIXX+'is_alpha',\n",
    "    'is_stop':SPACY_PREFIXX+'is_stop',\n",
    "    'is_pronoun':SPACY_PREFIXX+'is_pronoun',\n",
    "    'trailing_space':SPACY_PREFIXX+'trailing_space',\n",
    "}\n",
    "METAMAP_PREFIXX = \"[mm]\"\n",
    "METAMAP_COLUMN_NAME = {\n",
    "    'phrase': METAMAP_PREFIXX+'metamap_phrase',\n",
    "    'syntax_chunk': METAMAP_PREFIXX+'syntax_chunk|syntax_type|pos',\n",
    "    'concept': METAMAP_PREFIXX+'concept_group|CUI|prefered_name(hit_synonym)|categories|isHead|isNegated',\n",
    "    'neg_trigger': METAMAP_PREFIXX+'negation_group|target_token_indices|target_CUI',\n",
    "    'negated_target': METAMAP_PREFIXX+'negation_group|trigger_token_indices|target_CUI'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "from stanza.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "### WARNING: Overriding default model 2020AA with 2022AA.\n",
      "### WARNING: Overriding default model 2020AA with 2022AA.\n",
      "### WARNING: Overriding default model 2020AA with 2022AA.\n",
      "### WARNING: Overriding default model 2020AA with 2022AA.\n",
      "### WARNING: Overriding default model 2020AA with 2022AA.\n",
      "### WARNING: Overriding default model 2020AA with 2022AA.\n",
      "### WARNING: Overriding default model 2020AA with 2022AA.\n",
      "### WARNING: Overriding default model 2020AA with 2022AA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get response from Metamap in: 2.592735767364502s\n",
      "Finish Spacy+CoreNLP batch process in: 0.22222614288330078s\n",
      "Get response from Metamap in: 1.0275146961212158s\n",
      "Finish Spacy+CoreNLP batch process in: 0.09464192390441895s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "### WARNING: Overriding default model 2020AA with 2022AA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get response from Metamap in: 0.6471078395843506s\n",
      "Finish Spacy+CoreNLP batch process in: 0.11593055725097656s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "### WARNING: Overriding default model 2020AA with 2022AA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get response from Metamap in: 0.1795351505279541s\n",
      "Finish Spacy+CoreNLP batch process in: 0.08446192741394043s\n",
      "Get response from Metamap in: 0.33858418464660645s\n",
      "Finish Spacy+CoreNLP batch process in: 0.08787727355957031s\n",
      "Get response from Metamap in: 1.6917860507965088s\n",
      "Finish Spacy+CoreNLP batch process in: 0.0990900993347168s\n",
      "Get response from Metamap in: 0.0018148422241210938s\n",
      "Finish Spacy+CoreNLP batch process in: 0.09877872467041016s\n",
      "Get response from Metamap in: 1.425945520401001s\n",
      "Finish Spacy+CoreNLP batch process in: 0.2037642002105713s\n",
      "Get response from Metamap in: 0.5249402523040771s\n",
      "Finish Spacy+CoreNLP batch process in: 0.10130167007446289s\n",
      "Get response from Metamap in: 0.38230228424072266s\n",
      "Finish Spacy+CoreNLP batch process in: 0.0688333511352539s\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from multiprocessing import Lock\n",
    "from IPython.display import display, HTML\n",
    "import json, time\n",
    "import spacy\n",
    "import stanza\n",
    "from stanza.server import CoreNLPClient\n",
    "from stanza.pipeline.core import DownloadMethod\n",
    "\n",
    "# mp.cpu_count()\n",
    "METAMAP_CORES = 8\n",
    "STANZA_CORES = 8\n",
    "CORENLP_CORES = 8\n",
    "BATCH_SIZE = 10\n",
    "DATA_START_POS = 0 #8690\n",
    "DATA_END_POS = 100\n",
    "# DATA_END_INDEX = DATA_SIZE\n",
    "\n",
    "SECTION_FLAG = \"findings\"\n",
    "\n",
    "CORENLP_CUSTOM_PROPS = {\n",
    "    'annotators':'tokenize, ssplit, pos, lemma, ner, depparse, coref',\n",
    "    \"coref.algorithm\": \"statistical\"\n",
    "}\n",
    "\n",
    "STANZA_PROCESSOR_DICT = {\n",
    "    'tokenize': 'mimic', \n",
    "    'pos': 'mimic', \n",
    "    'lemma': 'mimic',\n",
    "    'depparse': 'mimic',\n",
    "    # 'sentiment':'sstplus', # Sentiment scores of 0, 1, or 2 (negative, neutral, positive).\n",
    "    'constituency': 'wsj', # wsj, wsj_bert, wsj_roberta\n",
    "    'ner': 'radiology',\n",
    "}\n",
    "\n",
    "nlp_spacy = spacy.load(\"en_core_web_md\", disable=['ner'])\n",
    "nlp_stanza = stanza.Pipeline('en', processors=STANZA_PROCESSOR_DICT, package=None, \n",
    "                      download_method=DownloadMethod.REUSE_RESOURCES,\n",
    "                      verbose=False) # logging_level='WARN'\n",
    "\n",
    "executor = ProcessPoolExecutor(max_workers=METAMAP_CORES)\n",
    "all_task = [executor.submit(run_metamap, startIndex, BATCH_SIZE) for startIndex in range(DATA_START_POS, DATA_END_POS, BATCH_SIZE)]\n",
    "\n",
    "\n",
    "lock=Lock()\n",
    "time0 = time.time()\n",
    "with CoreNLPClient(memory='8G', threads=CORENLP_CORES, endpoint='http://localhost:8801', \n",
    "                   be_quiet=True, properties=CORENLP_CUSTOM_PROPS) as client:\n",
    "    for future in as_completed(all_task):\n",
    "        time1 = time.time()\n",
    "        print(f\"Get response from Metamap in: {time1-time0}s\")\n",
    "        # Metamap\n",
    "        metamap_output, idx_inteval, input_list = future.result()\n",
    "        id_subList = id_list[idx_inteval[0]:idx_inteval[1]] \n",
    "        metamap_json_output = list(metamap_output.split(\"\\n\"))[1] # Only the second line is the required JSON string.\n",
    "        metamap_json_obj = json.loads(metamap_json_output)\n",
    "        parsed_obj_batch = parseMetamapJSON(metamap_json_obj, id_subList)\n",
    "        # print(classToJSON(parsed_obj_batch))\n",
    "        \n",
    "        # Stanza\n",
    "        # time2 = time.time()\n",
    "        # in_docs = []\n",
    "        # for record in parsed_obj_batch.records:\n",
    "        #     stanzaDoc = stanza.Document([], text=record.getFindingSection().text)\n",
    "        #     stanzaDoc._sid = record.sid\n",
    "        #     in_docs.append(stanzaDoc)\n",
    "        # # Call the neural pipeline on this list of documents\n",
    "        # # The output is also a list of stanza.Document objects, each output corresponding to an input Document object\n",
    "        # out_docs = nlp_stanza(in_docs) \n",
    "        # # print([i._sid for i in out_docs])\n",
    "        # time3 = time.time()\n",
    "        # print(f\"Finish Stanza batch process in: {time3-time2}s\")\n",
    "    \n",
    "        # SpaCy\n",
    "        time4 = time.time()\n",
    "        text_tuples = [(text,{\"record\":record}) for text, record in zip(input_list,parsed_obj_batch.records)]\n",
    "        for doc, context in nlp_spacy.pipe(text_tuples, as_tuples=True):\n",
    "            data = {\n",
    "                SPACY_COLUMN_NAME['token']: [tok.text for tok in doc],\n",
    "                SPACY_COLUMN_NAME['token_offset']: getTokenOffset(doc.text, doc),\n",
    "                SPACY_COLUMN_NAME['sentence_group']: align(doc, doc.sents),\n",
    "                SPACY_COLUMN_NAME['noun_chunk']: align(doc, doc.noun_chunks),\n",
    "                SPACY_COLUMN_NAME['lemma']: [tok.lemma_ for tok in doc],\n",
    "                SPACY_COLUMN_NAME['pos_core']: [f\"[{tok.pos_}]{spacy.explain(tok.pos_)}\" for tok in doc],\n",
    "                SPACY_COLUMN_NAME['pos_feature']: [f\"[{tok.tag_}]{spacy.explain(tok.tag_)}\" for tok in doc],\n",
    "                SPACY_COLUMN_NAME['dependency']: [f\"[{tok.dep_}]{spacy.explain(tok.dep_)}\" for tok in doc],\n",
    "                SPACY_COLUMN_NAME['dependency_head']: [tok.head.text for tok in doc],\n",
    "                SPACY_COLUMN_NAME['dependency_children']: [[child for child in tok.children] for tok in doc],\n",
    "                SPACY_COLUMN_NAME['morphology']: [tok.morph for tok in doc],\n",
    "                SPACY_COLUMN_NAME['is_alpha']: [tok.is_alpha for tok in doc],\n",
    "                SPACY_COLUMN_NAME['is_stop']: [tok.is_stop for tok in doc],\n",
    "                SPACY_COLUMN_NAME['is_pronoun']: [True if tok.pos_ == 'PRON' else False for tok in doc],\n",
    "                SPACY_COLUMN_NAME['trailing_space']: [True if tok.whitespace_ else False for tok in doc],\n",
    "            }\n",
    "            spacyOutput = pd.DataFrame(data=data)\n",
    "            \n",
    "            # Metamap\n",
    "            metamapRecord = context['record'] # the Record obj resolved from metamap output\n",
    "            # print(metamapRecord.sid)\n",
    "            # display(HTML(spacyOutput.to_html()))\n",
    "            phraseInfo, syntaxChunkInfo, conceptInfo, negTriggerInfo, negTargetInfo = formatMetamapRecord(metamapRecord)\n",
    "                \n",
    "            metamapOutput = pd.DataFrame({\n",
    "                METAMAP_COLUMN_NAME['phrase']: align_byIndex(doc, phraseInfo),\n",
    "                METAMAP_COLUMN_NAME['syntax_chunk']: align_byIndex_individually_withData_noOverlap(doc, syntaxChunkInfo),\n",
    "                METAMAP_COLUMN_NAME['concept']: align_byIndex_individually_withData(doc,conceptInfo),\n",
    "                METAMAP_COLUMN_NAME['neg_trigger']: align_byIndex_individually_withData(doc,negTriggerInfo),\n",
    "                METAMAP_COLUMN_NAME['negated_target']: align_byIndex_individually_withData(doc,negTargetInfo),\n",
    "            })\n",
    "            output = spacyOutput.join(metamapOutput)\n",
    "            \n",
    "            # CoreNLP\n",
    "            # time41 = time.time()\n",
    "            # document = client.annotate(metamapRecord.getFindingSection().text)\n",
    "            # time42 = time.time()\n",
    "            # print(f\"Get response from CoreNLP for single record in: {time42-time41}s\")\n",
    "            \n",
    "        time5 = time.time()\n",
    "        print(f\"Finish Spacy+CoreNLP batch process in: {time5-time4}s\")\n",
    "        time0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check metamap output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[sp]token</th>\n",
       "      <th>[sp]token_offset</th>\n",
       "      <th>[sp]sentence_group</th>\n",
       "      <th>[sp]noun_chunk</th>\n",
       "      <th>[sp]lemma</th>\n",
       "      <th>[sp]pos_core</th>\n",
       "      <th>[sp]pos_feature</th>\n",
       "      <th>[sp]dependency</th>\n",
       "      <th>[sp]dependency_head</th>\n",
       "      <th>[sp]dependency_children</th>\n",
       "      <th>[sp]morphology</th>\n",
       "      <th>[sp]is_alpha</th>\n",
       "      <th>[sp]is_stop</th>\n",
       "      <th>[sp]is_pronoun</th>\n",
       "      <th>[sp]trailing_space</th>\n",
       "      <th>[mm]metamap_phrase</th>\n",
       "      <th>[mm]syntax_chunk|syntax_type|pos</th>\n",
       "      <th>[mm]concept_group|CUI|prefered_name(hit_synonym)|categories|isHead|isNegated</th>\n",
       "      <th>[mm]negation_group|target_token_indices|target_CUI</th>\n",
       "      <th>[mm]negation_group|trigger_token_indices|target_CUI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>There</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>there</td>\n",
       "      <td>[PRON]pronoun</td>\n",
       "      <td>[EX]existential there</td>\n",
       "      <td>[expl]expletive</td>\n",
       "      <td>is</td>\n",
       "      <td>[]</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>12|adv|adv|['there']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   [sp]token  [sp]token_offset  [sp]sentence_group  [sp]noun_chunk [sp]lemma  \\\n",
       "14     There               102                   1              -1     there   \n",
       "\n",
       "     [sp]pos_core        [sp]pos_feature   [sp]dependency [sp]dependency_head  \\\n",
       "14  [PRON]pronoun  [EX]existential there  [expl]expletive                  is   \n",
       "\n",
       "   [sp]dependency_children [sp]morphology  [sp]is_alpha  [sp]is_stop  \\\n",
       "14                      []             ()          True         True   \n",
       "\n",
       "    [sp]is_pronoun  [sp]trailing_space  [mm]metamap_phrase  \\\n",
       "14            True                True                   8   \n",
       "\n",
       "   [mm]syntax_chunk|syntax_type|pos  \\\n",
       "14             12|adv|adv|['there']   \n",
       "\n",
       "   [mm]concept_group|CUI|prefered_name(hit_synonym)|categories|isHead|isNegated  \\\n",
       "14                                                 -1                             \n",
       "\n",
       "   [mm]negation_group|target_token_indices|target_CUI  \\\n",
       "14                                                 -1   \n",
       "\n",
       "   [mm]negation_group|trigger_token_indices|target_CUI  \n",
       "14                                                 -1   "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[output[SPACY_COLUMN_NAME['pos_core']].str.contains(\"PRON\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"/home/yuxiangliao/PhD/output/s53741303_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[sp]token</th>\n",
       "      <th>[sp]token_offset</th>\n",
       "      <th>[sp]sentence_group</th>\n",
       "      <th>[sp]noun_chunk</th>\n",
       "      <th>[sp]lemma</th>\n",
       "      <th>[sp]pos_core</th>\n",
       "      <th>[sp]pos_feature</th>\n",
       "      <th>[sp]dependency</th>\n",
       "      <th>[sp]dependency_head</th>\n",
       "      <th>[sp]dependency_children</th>\n",
       "      <th>[sp]morphology</th>\n",
       "      <th>[sp]is_alpha</th>\n",
       "      <th>[sp]is_stop</th>\n",
       "      <th>[sp]is_pronoun</th>\n",
       "      <th>[sp]trailing_space</th>\n",
       "      <th>[mm]metamap_phrase</th>\n",
       "      <th>[mm]syntax_chunk|syntax_type|pos</th>\n",
       "      <th>[mm]concept_group|CUI|prefered_name(hit_synonym)|categories|isHead|isNegated</th>\n",
       "      <th>[mm]negation_group|target_token_indices|target_CUI</th>\n",
       "      <th>[mm]negation_group|trigger_token_indices|target_CUI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pa</td>\n",
       "      <td>[NOUN]noun</td>\n",
       "      <td>[NN]noun, singular or mass</td>\n",
       "      <td>[nsubj]nominal subject</td>\n",
       "      <td>radiographs</td>\n",
       "      <td>[and, chest]</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0|head|noun|['pa']</td>\n",
       "      <td>[0|C3541314|Pairing Events Domain(PA)|inpr|1|0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>and</td>\n",
       "      <td>[CCONJ]coordinating conjunction</td>\n",
       "      <td>[CC]conjunction, coordinating</td>\n",
       "      <td>[cc]coordinating conjunction</td>\n",
       "      <td>PA</td>\n",
       "      <td>[]</td>\n",
       "      <td>(ConjType=Cmp)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1|conj|conj|['and']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lateral</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lateral</td>\n",
       "      <td>[ADJ]adjective</td>\n",
       "      <td>[JJ]adjective (English), other noun-modifier (Chinese)</td>\n",
       "      <td>[amod]adjectival modifier</td>\n",
       "      <td>chest</td>\n",
       "      <td>[]</td>\n",
       "      <td>(Degree=Pos)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2|mod|adj|['lateral']</td>\n",
       "      <td>[1|C0446472|Surface region of side of chest(Lateral chest)|blor|1|0, 2|C0205093|Lateral(LATERAL)|spco|0|0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chest</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>chest</td>\n",
       "      <td>[NOUN]noun</td>\n",
       "      <td>[NN]noun, singular or mass</td>\n",
       "      <td>[conj]conjunct</td>\n",
       "      <td>PA</td>\n",
       "      <td>[lateral]</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>3|head|noun|['chest', 'radiographs']</td>\n",
       "      <td>[1|C0446472|Surface region of side of chest(Lateral chest)|blor|1|0, 2|C0039985|Plain chest X-ray(chest Radiographs)|diap|1|0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>radiographs</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>radiograph</td>\n",
       "      <td>[NOUN]noun</td>\n",
       "      <td>[NNS]noun, plural</td>\n",
       "      <td>[ROOT]root</td>\n",
       "      <td>radiographs</td>\n",
       "      <td>[PA, again, demonstrate, .]</td>\n",
       "      <td>(Number=Plur)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>3|head|noun|['chest', 'radiographs']</td>\n",
       "      <td>[1|C1306645|Plain x-ray(Radiographs)|diap|1|0, 2|C0039985|Plain chest X-ray(chest Radiographs)|diap|1|0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>again</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>again</td>\n",
       "      <td>[ADV]adverb</td>\n",
       "      <td>[RB]adverb</td>\n",
       "      <td>[advmod]adverbial modifier</td>\n",
       "      <td>radiographs</td>\n",
       "      <td>[]</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>4|adv|adv|['again']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>demonstrate</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>demonstrate</td>\n",
       "      <td>[VERB]verb</td>\n",
       "      <td>[VBP]verb, non-3rd person singular present</td>\n",
       "      <td>[dep]unclassified dependent</td>\n",
       "      <td>radiographs</td>\n",
       "      <td>[hyperinflation]</td>\n",
       "      <td>(Tense=Pres, VerbForm=Fin)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>5|verb|verb|['demonstrate']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>severe</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>severe</td>\n",
       "      <td>[ADJ]adjective</td>\n",
       "      <td>[JJ]adjective (English), other noun-modifier (Chinese)</td>\n",
       "      <td>[amod]adjectival modifier</td>\n",
       "      <td>hyperinflation</td>\n",
       "      <td>[]</td>\n",
       "      <td>(Degree=Pos)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>6|mod|adj|['severe']</td>\n",
       "      <td>[3|C0205082|Severe (severity modifier)(SEVERE)|fndg|0|0, 4|C0334048|Severe dysplasia(Severe)|comd|0|0, 5|C4050465|Severe Extremity Pain(Severe)|fndg|0|0, 6|C4050466|Borg Category-Ratio 10 Perceived Exertion Score 5(Severe)|fndg|0|0, 7|C4722466|Severe Hallucination(Severe)|fndg|0|0, 8|C4761449|Epidermal cGVHD Score 4(Severe)|fndg|0|0, 9|C5203119|Intensity and Distress 5(Severe)|fndg|0|0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hyperinflation</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>hyperinflation</td>\n",
       "      <td>[NOUN]noun</td>\n",
       "      <td>[NN]noun, singular or mass</td>\n",
       "      <td>[dobj]direct object</td>\n",
       "      <td>demonstrate</td>\n",
       "      <td>[severe, and, bronchiectasis]</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>7|head|noun|['hyperinflation']</td>\n",
       "      <td>[3|C0020449|Hyperdistention(Hyperinflation)|anab|1|0, 4|C0020449|Hyperdistention(Hyperinflation)|anab|1|0, 5|C0020449|Hyperdistention(Hyperinflation)|anab|1|0, 6|C0020449|Hyperdistention(Hyperinflation)|anab|1|0, 7|C0020449|Hyperdistention(Hyperinflation)|anab|1|0, 8|C0020449|Hyperdistention(Hyperinflation)|anab|1|0, 9|C0020449|Hyperdistention(Hyperinflation)|anab|1|0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>and</td>\n",
       "      <td>[CCONJ]coordinating conjunction</td>\n",
       "      <td>[CC]conjunction, coordinating</td>\n",
       "      <td>[cc]coordinating conjunction</td>\n",
       "      <td>hyperinflation</td>\n",
       "      <td>[]</td>\n",
       "      <td>(ConjType=Cmp)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>8|conj|conj|['and']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>diffuse</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>diffuse</td>\n",
       "      <td>[NOUN]noun</td>\n",
       "      <td>[NN]noun, singular or mass</td>\n",
       "      <td>[compound]compound</td>\n",
       "      <td>bronchiectasis</td>\n",
       "      <td>[]</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>9|mod|adj|['diffuse']</td>\n",
       "      <td>[10|C0205219|Diffuse(DIFFUSE)|spco|0|0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bronchiectasis</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>bronchiectasis</td>\n",
       "      <td>[NOUN]noun</td>\n",
       "      <td>[NN]noun, singular or mass</td>\n",
       "      <td>[conj]conjunct</td>\n",
       "      <td>hyperinflation</td>\n",
       "      <td>[diffuse]</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>10|head|noun|['bronchiectasis']</td>\n",
       "      <td>[10|C0006267|Bronchiectasis(BRONCHIECTASIS)|dsyn|1|0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>.</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>[PUNCT]punctuation</td>\n",
       "      <td>[.]punctuation mark, sentence closer</td>\n",
       "      <td>[punct]punctuation</td>\n",
       "      <td>radiographs</td>\n",
       "      <td>[ ]</td>\n",
       "      <td>(PunctType=Peri)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>11|punc||['.']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>[SPACE]space</td>\n",
       "      <td>[_SP]whitespace</td>\n",
       "      <td>[dep]unclassified dependent</td>\n",
       "      <td>.</td>\n",
       "      <td>[]</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>There</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>there</td>\n",
       "      <td>[PRON]pronoun</td>\n",
       "      <td>[EX]existential there</td>\n",
       "      <td>[expl]expletive</td>\n",
       "      <td>is</td>\n",
       "      <td>[]</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>12|adv|adv|['there']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>is</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>be</td>\n",
       "      <td>[VERB]verb</td>\n",
       "      <td>[VBZ]verb, 3rd person singular present</td>\n",
       "      <td>[ROOT]root</td>\n",
       "      <td>is</td>\n",
       "      <td>[There, consolidation, .]</td>\n",
       "      <td>(Mood=Ind, Number=Sing, Person=3, Tense=Pres, VerbForm=Fin)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>13|aux|aux|['is']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>no</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>[DET]determiner</td>\n",
       "      <td>[DT]determiner</td>\n",
       "      <td>[det]determiner</td>\n",
       "      <td>consolidation</td>\n",
       "      <td>[]</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>14|det|det|['no']</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0|18|C0521530, 1|20,21|C2073625,C4552777,C0032227, 2|24|C1963215,C0032326]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>focal</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>focal</td>\n",
       "      <td>[ADJ]adjective</td>\n",
       "      <td>[JJ]adjective (English), other noun-modifier (Chinese)</td>\n",
       "      <td>[amod]adjectival modifier</td>\n",
       "      <td>consolidation</td>\n",
       "      <td>[]</td>\n",
       "      <td>(Degree=Pos)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>15|mod|adj|['focal']</td>\n",
       "      <td>[11|C0205234|Focal(FOCAL)|spco|0|0, 12|C0205234|Focal(FOCAL)|spco|0|0, 13|C0205234|Focal(FOCAL)|spco|0|0, 14|C0205234|Focal(FOCAL)|spco|0|0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>consolidation</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>consolidation</td>\n",
       "      <td>[NOUN]noun</td>\n",
       "      <td>[NN]noun, singular or mass</td>\n",
       "      <td>[attr]attribute</td>\n",
       "      <td>is</td>\n",
       "      <td>[no, focal, ,, effusion]</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>16|head|noun|['consolidation']</td>\n",
       "      <td>[11|C0521530|Lung consolidation(Consolidation)|dsyn|1|1, 12|C0702116|Consolidation(Consolidation)|qlco|1|0, 13|C1511484|Consolidation Therapy(Consolidation)|topp|1|0, 14|C4722412|Consolidation Clinical Trial Setting(CONSOLIDATION)|hcro,mnob|1|0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0|16|C0521530]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>,</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>,</td>\n",
       "      <td>[PUNCT]punctuation</td>\n",
       "      <td>[,]punctuation mark, comma</td>\n",
       "      <td>[punct]punctuation</td>\n",
       "      <td>consolidation</td>\n",
       "      <td>[]</td>\n",
       "      <td>(PunctType=Comm)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>17|punc||[',']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pleural</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>pleural</td>\n",
       "      <td>[ADJ]adjective</td>\n",
       "      <td>[JJ]adjective (English), other noun-modifier (Chinese)</td>\n",
       "      <td>[amod]adjectival modifier</td>\n",
       "      <td>effusion</td>\n",
       "      <td>[]</td>\n",
       "      <td>(Degree=Pos)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>18|head|noun|['pleural', 'effusion']</td>\n",
       "      <td>[15|C0032227|Pleural effusion disorder(PLEURAL EFFUSION)|dsyn|1|1, 16|C1253943|Pleural effusion fluid(Pleural effusion)|bdsu|1|0, 17|C2073625|x-ray of chest: pleural effusion(pleural effusion)|fndg|1|1, 18|C4552777|Pleural Effusion, CTCAE(Pleural Effusion)|fndg|1|1]</td>\n",
       "      <td>-1</td>\n",
       "      <td>[1|16|C2073625,C4552777,C0032227]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>effusion</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>effusion</td>\n",
       "      <td>[NOUN]noun</td>\n",
       "      <td>[NN]noun, singular or mass</td>\n",
       "      <td>[conj]conjunct</td>\n",
       "      <td>consolidation</td>\n",
       "      <td>[pleural, ,, or, pneumothorax]</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>18|head|noun|['pleural', 'effusion']</td>\n",
       "      <td>[15|C0032227|Pleural effusion disorder(PLEURAL EFFUSION)|dsyn|1|1, 16|C1253943|Pleural effusion fluid(Pleural effusion)|bdsu|1|0, 17|C2073625|x-ray of chest: pleural effusion(pleural effusion)|fndg|1|1, 18|C4552777|Pleural Effusion, CTCAE(Pleural Effusion)|fndg|1|1]</td>\n",
       "      <td>-1</td>\n",
       "      <td>[1|16|C2073625,C4552777,C0032227]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>,</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>,</td>\n",
       "      <td>[PUNCT]punctuation</td>\n",
       "      <td>[,]punctuation mark, comma</td>\n",
       "      <td>[punct]punctuation</td>\n",
       "      <td>effusion</td>\n",
       "      <td>[]</td>\n",
       "      <td>(PunctType=Comm)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>19|punc||[',']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>or</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>or</td>\n",
       "      <td>[CCONJ]coordinating conjunction</td>\n",
       "      <td>[CC]conjunction, coordinating</td>\n",
       "      <td>[cc]coordinating conjunction</td>\n",
       "      <td>effusion</td>\n",
       "      <td>[]</td>\n",
       "      <td>(ConjType=Cmp)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>20|conj|conj|['or']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pneumothorax</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>pneumothorax</td>\n",
       "      <td>[NOUN]noun</td>\n",
       "      <td>[NN]noun, singular or mass</td>\n",
       "      <td>[conj]conjunct</td>\n",
       "      <td>effusion</td>\n",
       "      <td>[]</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>21|head|noun|['pneumothorax']</td>\n",
       "      <td>[19|C0032326|Pneumothorax(PNEUMOTHORAX)|dsyn|1|1, 20|C1963215|Pneumothorax, CTCAE(Pneumothorax)|fndg|1|1]</td>\n",
       "      <td>-1</td>\n",
       "      <td>[2|16|C1963215,C0032326]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>.</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>[PUNCT]punctuation</td>\n",
       "      <td>[.]punctuation mark, sentence closer</td>\n",
       "      <td>[punct]punctuation</td>\n",
       "      <td>is</td>\n",
       "      <td>[ ]</td>\n",
       "      <td>(PunctType=Peri)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>22|punc||['.']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>[SPACE]space</td>\n",
       "      <td>[_SP]whitespace</td>\n",
       "      <td>[dep]unclassified dependent</td>\n",
       "      <td>.</td>\n",
       "      <td>[]</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The</td>\n",
       "      <td>171</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>the</td>\n",
       "      <td>[DET]determiner</td>\n",
       "      <td>[DT]determiner</td>\n",
       "      <td>[det]determiner</td>\n",
       "      <td>silhouette</td>\n",
       "      <td>[]</td>\n",
       "      <td>(Definite=Def, PronType=Art)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>23|det|det|['the']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cardiomediastinal</td>\n",
       "      <td>175</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>cardiomediastinal</td>\n",
       "      <td>[ADJ]adjective</td>\n",
       "      <td>[JJ]adjective (English), other noun-modifier (Chinese)</td>\n",
       "      <td>[amod]adjectival modifier</td>\n",
       "      <td>silhouette</td>\n",
       "      <td>[]</td>\n",
       "      <td>(Degree=Pos)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>24|mod|adj|['cardiomediastinal']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>silhouette</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>silhouette</td>\n",
       "      <td>[NOUN]noun</td>\n",
       "      <td>[NN]noun, singular or mass</td>\n",
       "      <td>[nsubj]nominal subject</td>\n",
       "      <td>is</td>\n",
       "      <td>[The, cardiomediastinal]</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>25|head|noun|['silhouette']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>is</td>\n",
       "      <td>204</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>be</td>\n",
       "      <td>[AUX]auxiliary</td>\n",
       "      <td>[VBZ]verb, 3rd person singular present</td>\n",
       "      <td>[ROOT]root</td>\n",
       "      <td>is</td>\n",
       "      <td>[silhouette, stable, .]</td>\n",
       "      <td>(Mood=Ind, Number=Sing, Person=3, Tense=Pres, VerbForm=Fin)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>26|aux|aux|['is']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>stable</td>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>stable</td>\n",
       "      <td>[ADJ]adjective</td>\n",
       "      <td>[JJ]adjective (English), other noun-modifier (Chinese)</td>\n",
       "      <td>[acomp]adjectival complement</td>\n",
       "      <td>is</td>\n",
       "      <td>[]</td>\n",
       "      <td>(Degree=Pos)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>27|head|adj|['stable']</td>\n",
       "      <td>[21|C0205360|Stable status(STABLE)|qlco|1|0, 22|C1547311|Patient Condition Code - Stable(Stable)|inpr|1|0]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>.</td>\n",
       "      <td>213</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>[PUNCT]punctuation</td>\n",
       "      <td>[.]punctuation mark, sentence closer</td>\n",
       "      <td>[punct]punctuation</td>\n",
       "      <td>is</td>\n",
       "      <td>[]</td>\n",
       "      <td>(PunctType=Peri)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>28|punc||['.']</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(output.to_html()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:corenlp]",
   "language": "python",
   "name": "conda-env-corenlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
