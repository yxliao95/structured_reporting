{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "from loguru import logger\n",
    "\n",
    "LOG_ROOT = os.path.abspath(\"./\")\n",
    "LOG_FILE = LOG_ROOT + \"/logs/mimic-cxr.log\"\n",
    "\n",
    "# Remove all handlers and reset stderr\n",
    "logger.remove(handler_id=None)\n",
    "logger.add(\n",
    "    LOG_FILE,\n",
    "    level=\"TRACE\",\n",
    "    mode=\"w\",\n",
    "    backtrace=False,\n",
    "    diagnose=True,\n",
    "    colorize=False,\n",
    "    format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}\",\n",
    ")\n",
    "logger.info(\"\\r\\n\" + \">\" * 29 + \"\\r\\n\" + \">>> New execution started >>>\" + \"\\r\\n\" + \">\" * 29)\n",
    "# To filter log level: TRACE=5, DEBUG=10, INFO=20, SUCCESS=25, WARNING=30, ERROR=40, CRITICAL=50\n",
    "logger.add(sys.stdout, level=\"INFO\", filter=lambda record: record[\"level\"].no < 40, colorize=True)\n",
    "logger.add(sys.stderr, level=\"ERROR\", backtrace=False, diagnose=True, colorize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read From Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pid        sid  \\\n",
      "0       p10000032  s50414267   \n",
      "1       p10000032  s53189527   \n",
      "2       p10000032  s53911762   \n",
      "3       p10000032  s56699142   \n",
      "4       p10000764  s57375967   \n",
      "...           ...        ...   \n",
      "227830  p19999442  s58708861   \n",
      "227831  p19999733  s57132437   \n",
      "227832  p19999987  s55368167   \n",
      "227833  p19999987  s58621812   \n",
      "227834  p19999987  s58971208   \n",
      "\n",
      "                                                 findings  \\\n",
      "0       There is no focal consolidation, pleural effus...   \n",
      "1       The cardiac, mediastinal and hilar contours ar...   \n",
      "2       Single frontal view of the chest provided. \\n ...   \n",
      "3       The lungs are clear of focal consolidation, pl...   \n",
      "4       PA and lateral views of the chest provided.   ...   \n",
      "...                                                   ...   \n",
      "227830  ET tube ends 4.7 cm above the carina.  NG tube...   \n",
      "227831  The lungs are clear, and the cardiomediastinal...   \n",
      "227832  There has been interval extubation and improve...   \n",
      "227833  Portable supine AP view of the chest provided ...   \n",
      "227834  The ET tube terminates approximately 2.9 cm fr...   \n",
      "\n",
      "                                               impression  \\\n",
      "0                     No acute cardiopulmonary process.\\n   \n",
      "1                 No acute cardiopulmonary abnormality.\\n   \n",
      "2                       No acute intrathoracic process.\\n   \n",
      "3                     No acute cardiopulmonary process.\\n   \n",
      "4       Focal consolidation at the left lung base, pos...   \n",
      "...                                                   ...   \n",
      "227830  1.  Lines and tubes are in adequate position. ...   \n",
      "227831                 No acute cardiothoracic process.\\n   \n",
      "227832                                                      \n",
      "227833  Appropriately positioned ET and NG tubes.  Bib...   \n",
      "227834  Slight interval worsening of right lower lung ...   \n",
      "\n",
      "       provisional_findings_impression findings_and_impression  \\\n",
      "0                                                                \n",
      "1                                                                \n",
      "2                                                                \n",
      "3                                                                \n",
      "4                                                                \n",
      "...                                ...                     ...   \n",
      "227830                                                           \n",
      "227831                                                           \n",
      "227832                                                           \n",
      "227833                                                           \n",
      "227834                                                           \n",
      "\n",
      "                                     clinical_information  \\\n",
      "0       @[INDICATION]\\n___F with new onset ascites  //...   \n",
      "1       @[INDICATION]\\nHistory: ___F with shortness of...   \n",
      "2       @[INDICATION]\\n___F with cough  // acute proce...   \n",
      "3       @[INDICATION]\\n___ year old woman with cirrhos...   \n",
      "4       @[INDICATION]\\n___M with hypoxia  // ?pna, asp...   \n",
      "...                                                   ...   \n",
      "227830  @[INDICATION]\\nPatient with intubation, evalua...   \n",
      "227831     @[INDICATION]\\n___-year-old with chest pain.\\n   \n",
      "227832                                                      \n",
      "227833  @[CLINICAL HISTORY]\\nTransfer from outside hos...   \n",
      "227834  @[INDICATION]\\n___-year-old female intubated f...   \n",
      "\n",
      "                                    procedure_information  \\\n",
      "0       @[EXAMINATION]\\nCHEST (PA AND LAT)\\n@[TECHNIQU...   \n",
      "1       @[EXAMINATION]\\nCHEST (PA AND LAT)\\n@[TECHNIQU...   \n",
      "2                   @[EXAMINATION]\\nCHEST (PORTABLE AP)\\n   \n",
      "3       @[TECHNIQUE]\\nFrontal chest radiographs were o...   \n",
      "4                    @[EXAMINATION]\\nCHEST (PA AND LAT)\\n   \n",
      "...                                                   ...   \n",
      "227830                                                      \n",
      "227831  @[TECHNIQUE]\\nFrontal and lateral radiographs ...   \n",
      "227832                                                      \n",
      "227833                                                      \n",
      "227834  @[TECHNIQUE]\\nSingle AP portable exam on the c...   \n",
      "\n",
      "                                               comparison addendum wet_read  \\\n",
      "0                                  @[COMPARISON]\\nNone.\\n                     \n",
      "1                                    @[COMPARISON]\\n___\\n                     \n",
      "2                   @[COMPARISON]\\nChest radiograph ___\\n                     \n",
      "3       @[COMPARISON]\\nRadiographs from ___, ___ and _...                     \n",
      "4                                   @[COMPARISON]\\nNone\\n                     \n",
      "...                                                   ...      ...      ...   \n",
      "227830                             @[COMPARISON]\\nNone.\\n                     \n",
      "227831                             @[COMPARISON]\\nNone.\\n                     \n",
      "227832                   @[COMPARISON]\\n___ radiograph.\\n                     \n",
      "227833  @[COMPARISON]\\nPrior chest radiograph from ear...                     \n",
      "227834      @[COMPARISONS]\\nChest radiographs from ___.\\n                     \n",
      "\n",
      "                                                unknown  \n",
      "0                                                        \n",
      "1                                                        \n",
      "2                                                        \n",
      "3                                                        \n",
      "4                                                        \n",
      "...                                                 ...  \n",
      "227830            @[UNKNOWN]\\nPORTABLE AP CHEST X-RAY\\n  \n",
      "227831                                                   \n",
      "227832              @[UNKNOWN]\\nPORTABLE CHEST OF ___\\n  \n",
      "227833  @[UNKNOWN]\\nCHEST RADIOGRAPH PERFORMED ON ___\\n  \n",
      "227834                                                   \n",
      "\n",
      "[227835 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "# DB connect\n",
    "DB = pymysql.connect(host=\"127.0.0.1\", port=3306, user=\"root\", password=\"1121\", db=\"radiology_datasets\", charset=\"utf8\")\n",
    "CURSOR = DB.cursor(cursor=pymysql.cursors.DictCursor)\n",
    "\n",
    "sql_select = \"SELECT * FROM radiology_datasets.`mimic-cxr_manual`;\"\n",
    "\n",
    "CURSOR.execute(sql_select)\n",
    "df = pd.DataFrame(CURSOR.fetchall())\n",
    "print(df)\n",
    "\n",
    "CURSOR.close()\n",
    "DB.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove heading labels\n",
    "@[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def removeHeadingLabels(content):\n",
    "    reStr = r\"@\\[.*?\\]\"\n",
    "    content = re.sub(reStr,\"\",content)\n",
    "    return content.strip()\n",
    "\n",
    "def find_headingLabels(content):\n",
    "    reStr = r\"@\\[.*?\\]\"\n",
    "    m = re.findall(reStr,content)\n",
    "    return m\n",
    "\n",
    "def headingLabelsCounter(content):\n",
    "    return len(find_headingLabels(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections counting\n",
    "Results: \n",
    "\n",
    "Regarding the findings, impression, PFI, and FAI sections, 217,240 reports have at least one of the findings or impression section. As for the rest, 10,588 reports have the FAI section. Only 7 reports have no content. \n",
    "\n",
    "227,835 reports in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reports: 227835\n",
      "Reports that \n",
      "    contain the FINDINGS section: 156260\n",
      "    contain the IMPRESSION section: 189493\n",
      "    contain the PFI section: 200\n",
      "    contain the FAI section: 10591\n",
      "    contain at least one of the FINDINGS or IMPRESSION section: 217240\n",
      "    contain both the FINDINGS and IMPRESSION sections: 128513\n",
      "    have at least one of the PFI or FAI section: 10588\n",
      "    have both the PFI and FAI sections: 2\n",
      "\n",
      "Reports that do not contain the provisional_findings_impression or findings_and_impression sections, but \n",
      "    contain at least one of the FINDINGS or IMPRESSION section: 217039\n",
      "    contain both the FINDINGS and IMPRESSION sections: 128317\n",
      "    only contain the FINDINGS section: 27745\n",
      "    only contain the IMPRESSION section: 60977\n",
      "\n",
      "Reports that do not contain the FINDINGS or IMPRESSION section, but\n",
      "    have at least one of the PFI or FAI section: 10588\n",
      "    have both the PFI and FAI sections: 2\n",
      "    only have the PFI section: 0\n",
      "    only have the FAI section: 10586\n",
      "Empty reports: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reports: {df.shape[0]}\")\n",
    "\n",
    "print(\"Reports that \")\n",
    "df_F = df.query(\"findings != ''\")\n",
    "print(f\"    contain the FINDINGS section: {df_F.shape[0]}\")\n",
    "\n",
    "df_I = df.query(\"impression != ''\")\n",
    "print(f\"    contain the IMPRESSION section: {df_I.shape[0]}\")\n",
    "\n",
    "df_PFI = df.query(\"provisional_findings_impression != ''\")\n",
    "print(f\"    contain the PFI section: {df_PFI.shape[0]}\")\n",
    "\n",
    "df_FAI = df.query(\"findings_and_impression != ''\")\n",
    "print(f\"    contain the FAI section: {df_FAI.shape[0]}\")\n",
    "\n",
    "df_F_or_I = df.query(\"(findings != '' | impression != '')\")\n",
    "print(f\"    contain at least one of the FINDINGS or IMPRESSION section: {df_F_or_I.shape[0]}\")\n",
    "\n",
    "df_F_I = df.query(\"(findings != '' & impression != '')\")\n",
    "print(f\"    contain both the FINDINGS and IMPRESSION sections: {df_F_I.shape[0]}\")\n",
    "\n",
    "df_noF_noI_PFI_or_FAI = df.query(\"(findings == '' & impression == '') & (provisional_findings_impression != '' | findings_and_impression != '')\")\n",
    "print(f\"    have at least one of the PFI or FAI section: {df_noF_noI_PFI_or_FAI.shape[0]}\")\n",
    "\n",
    "df_noF_noI_PFI_FAI = df.query(\"(findings == '' & impression == '') & (provisional_findings_impression != '' & findings_and_impression != '')\")\n",
    "print(f\"    have both the PFI and FAI sections: {df_noF_noI_PFI_FAI.shape[0]}\")\n",
    "\n",
    "\n",
    "print(\"\\nReports that do not contain the provisional_findings_impression or findings_and_impression sections, but \")\n",
    "df_noPFI_noFAI_F_or_I = df.query(\"(findings != '' | impression != '') & (provisional_findings_impression == '' & findings_and_impression == '')\")\n",
    "print(f\"    contain at least one of the FINDINGS or IMPRESSION section: {df_noPFI_noFAI_F_or_I.shape[0]}\")\n",
    "\n",
    "df_noPFI_noFAI_F_I = df.query(\"(findings != '' & impression != '') & (provisional_findings_impression == '' & findings_and_impression == '')\")\n",
    "print(f\"    contain both the FINDINGS and IMPRESSION sections: {df_noPFI_noFAI_F_I.shape[0]}\")\n",
    "\n",
    "df_noPFI_noFAI_F_only = df.query(\"findings != '' & impression == '' & provisional_findings_impression == '' & findings_and_impression == ''\")\n",
    "print(f\"    only contain the FINDINGS section: {df_noPFI_noFAI_F_only.shape[0]}\")\n",
    "\n",
    "df_noPFI_noFAI_I_only = df.query(\"findings == '' & impression != '' & provisional_findings_impression == '' & findings_and_impression == ''\")\n",
    "print(f\"    only contain the IMPRESSION section: {df_noPFI_noFAI_I_only.shape[0]}\")\n",
    "\n",
    "\n",
    "print(\"\\nReports that do not contain the FINDINGS or IMPRESSION section, but\")\n",
    "df_noF_noI_PFI_or_FAI = df.query(\"(findings == '' & impression == '') & (provisional_findings_impression != '' | findings_and_impression != '')\")\n",
    "print(f\"    have at least one of the PFI or FAI section: {df_noF_noI_PFI_or_FAI.shape[0]}\")\n",
    "\n",
    "df_noF_noI_PFI_FAI = df.query(\"(findings == '' & impression == '') & (provisional_findings_impression != '' & findings_and_impression != '')\")\n",
    "print(f\"    have both the PFI and FAI sections: {df_noF_noI_PFI_FAI.shape[0]}\")\n",
    "\n",
    "df_noF_noI_PFI_only = df.query(\"findings == '' & impression == '' & provisional_findings_impression != '' & findings_and_impression == ''\")\n",
    "print(f\"    only have the PFI section: {df_noF_noI_PFI_only.shape[0]}\")\n",
    "\n",
    "df_noF_noI_FAI_only = df.query(\"findings == '' & impression == '' & provisional_findings_impression == '' & findings_and_impression != ''\")\n",
    "print(f\"    only have the FAI section: {df_noF_noI_FAI_only.shape[0]}\")\n",
    "\n",
    "\n",
    "df_empty = df.query(\"findings == '' & impression == '' & provisional_findings_impression == '' & findings_and_impression == ''\")\n",
    "print(f\"Empty reports: {df_empty.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Having multiple labels in one section\n",
    "\n",
    "Result: \n",
    "\n",
    "No more than 1 heading per section. The four heading labels in the impression section are \"@[manual]\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reports that have more that one heading labels in the same section:\n",
      "    findings, label_num > 0: 0\n",
      "    impression, label_num > 0: 4\n",
      "    provisional_findings_impression, label_num > 1: 0\n",
      "    findings_and_impression, label_num > 1: 0\n"
     ]
    }
   ],
   "source": [
    "df_num = df.loc[:,'findings':'findings_and_impression'].applymap(lambda ele: headingLabelsCounter(str(ele)))\n",
    "f_gt_1 = df_num.loc[lambda _df: _df['findings'] > 0].shape\n",
    "i_gt_1 = df_num.loc[lambda _df: _df['impression'] > 0].shape\n",
    "pfi_gt_1 = df_num.loc[lambda _df: _df['provisional_findings_impression'] > 1].shape\n",
    "fai_gt_1 = df_num.loc[lambda _df: _df['findings_and_impression'] > 1].shape\n",
    "\n",
    "print(\"Reports that have more that one heading labels in the same section:\")\n",
    "print(f\"    findings, label_num > 0: {f_gt_1[0]}\")\n",
    "print(f\"    impression, label_num > 0: {i_gt_1[0]}\")\n",
    "print(f\"    provisional_findings_impression, label_num > 1: {pfi_gt_1[0]}\")\n",
    "print(f\"    findings_and_impression, label_num > 1: {fai_gt_1[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To JSON/XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_labels = df.loc[:,'pid':'findings_and_impression'].applymap(lambda ele: removeHeadingLabels(str(ele)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_labels.to_json(os.path.join(os.path.abspath(\"./\"),\"mimic_cxr_reports_core.json\"),orient=\"records\",lines=True)\n",
    "# df_no_labels.to_xml(os.path.join(os.path.abspath(\"./\"),\"mimic_cxr_reports_core.xml\"),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization & Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input rows: 3738313\n",
      "After filter: 3738246\n"
     ]
    }
   ],
   "source": [
    "ent_files = ['findings.txt','impression.txt','FAI.txt','PFI.txt']\n",
    "ent_list = []\n",
    "for ent_file in ent_files:\n",
    "    with open('/Users/liao/myProjects/VSCode_workspace/structured_reporting/statistic/'+ent_file,'r') as f:\n",
    "        ent_list.extend(f.readlines())\n",
    "print(f\"Input rows: {len(ent_list)}\")      \n",
    "def filterFunc(x):\n",
    "    try:\n",
    "        m = re.match(r\"s\\d+:\",x)\n",
    "        m.group()\n",
    "        return True\n",
    "    except AttributeError:\n",
    "        return False\n",
    "ent_list = list(filter(filterFunc,ent_list))\n",
    "print(f\"After filter: {len(ent_list)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85180\n",
      "('pneumothorax', 112997)\n",
      "('pleural effusion', 91543)\n",
      "('lungs', 52227)\n",
      "('acute', 46120)\n",
      "('unchanged', 43721)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "entCounter = Counter([row.split(\":\")[1].strip() for row in ent_list])\n",
    "print(len(entCounter))\n",
    "for i in entCounter.most_common(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data_list = [['Entity','Counting']]\n",
    "for ent,num in entCounter.most_common():\n",
    "    data_list.append([ent,num])\n",
    "\n",
    "with open(\"ent.csv\",mode=\"w\",newline=\"\") as f:\n",
    "    csv.writer(f).writerows(data_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbe186fad143582492f874971b555a6a67ca040c11267037e80d88fc47d0fa6d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
